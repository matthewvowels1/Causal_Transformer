{
 "cells": [
  {
   "cell_type": "code",
   "id": "f84f0be0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T13:39:19.505649Z",
     "start_time": "2024-10-01T13:39:18.146522Z"
    }
   },
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import torch\n",
    "from model import CaT\n",
    "from CaT.datasets import reorder_dag, get_full_ordering\n",
    "from utils.inference import CausalInference\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import get_full_ordering, reorder_dag\n",
    "\n",
    "shuffling = 0\n",
    "seed = 1\n",
    "standardize = 0\n",
    "sample_size = 100000\n",
    "batch_size = 100\n",
    "max_iters = 50000\n",
    "eval_interval = 100\n",
    "eval_iters = 100\n",
    "validation_fraction = 0.3\n",
    "np.random.seed(seed=seed)\n",
    "torch.manual_seed(seed)\n",
    "device = 'cuda'\n",
    "dropout_rate = 0.0\n",
    "learning_rate = 5e-3\n",
    "ff_n_embed = 30\n",
    "num_heads = 2\n",
    "n_layers = 2\n",
    "embed_dim = 30\n",
    "head_size = 30\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "37367d6c",
   "metadata": {},
   "source": [
    "We create data from a 'true' DAG (which is DAGnx3 below) but also provide two other DAGs which are incorrect in different ways. DAGnx1 is fully exogenous, and DAGnx2 has one missing edge and another directed edge reversed.\n",
    "\n",
    "We imagine we are interested in the 'total' effect of X -> Y.  As these simulations are linear, this effect can be calculated easily by hand.\n",
    "\n",
    "In the case where X1 -> Y and X1 -> X2 -> Y, the total effect is the sum of the effect from both paths. e.g. if X1 -> Y has a coefficient of  0.8,  X1 -> X2 of 0.8, and X2 -> Y of 0.4, then the total effect is 0.8 + (0.8 x 0.4) = 1.12"
   ]
  },
  {
   "cell_type": "code",
   "id": "5de6b09c-fb7a-4a95-ab23-954550e69e24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T13:39:19.651830Z",
     "start_time": "2024-10-01T13:39:19.507116Z"
    }
   },
   "source": [
    "def generate_data(N, d=1):\n",
    "    DAGnx1 = nx.DiGraph()\n",
    "    DAGnx2 = nx.DiGraph()\n",
    "    DAGnx3 = nx.DiGraph()  # correct graph\n",
    "    \n",
    "    Ux1 = np.random.randn(N,d)\n",
    "    X1 =  Ux1\n",
    "\n",
    "    Ux2 = np.random.randn(N,d)\n",
    "    X2 =  0.8 * X1 + Ux2\n",
    "    \n",
    "    X20 = Ux2\n",
    "    X21 = 0.8 + Ux2\n",
    "\n",
    "    Uy = np.random.randn(N,d)\n",
    "    Y =  0.8 * X1 + 0.4 * X2 + Uy  # 0.4*0.8   + 0.8 = 1.12  Total effect\n",
    "    \n",
    "    Ux3 = np.random.randn(N,d)\n",
    "    X3 = 0.7 * Y + 0.6 * X1 + Ux3\n",
    "\n",
    "    Y0 = 0.4 * X20 + Uy \n",
    "    Y1 = 0.8 + 0.4 * X21 + Uy\n",
    "\n",
    "    all_data_dict = {'X1': X1, 'X2': X2, 'X3': X3, 'Y': Y}\n",
    "\n",
    "    # types can be 'cat' (categorical) 'cont' (continuous) or 'bin' (binary)\n",
    "    var_types = {'X1': 'cont', 'X2': 'cont', 'X3': 'cont', 'Y': 'cont'}\n",
    "\n",
    "    DAGnx1.add_edges_from([('X1', 'Y'), ('X2', 'Y'), ('X3', 'Y')])\n",
    "    DAGnx1 = reorder_dag(dag=DAGnx1)  # topologically sorted dag\n",
    "    var_names1 = list(DAGnx1.nodes())  # topologically ordered list of variables\n",
    "    all_data1 = np.stack([all_data_dict[key] for key in var_names1], axis=1)\n",
    "    causal_ordering1 = get_full_ordering(DAGnx1)\n",
    "    ex_dag_stuff = (all_data1, DAGnx1, var_names1, causal_ordering1, var_types)\n",
    "    \n",
    "    DAGnx2.add_edges_from([('X1', 'Y'), ('X1', 'X2'), ('X2', 'Y'), ('X3', 'Y')])\n",
    "    DAGnx2 = reorder_dag(dag=DAGnx2)  # topologically sorted dag\n",
    "    var_names2 = list(DAGnx2.nodes())  # topologically ordered list of variables\n",
    "    all_data2 = np.stack([all_data_dict[key] for key in var_names2], axis=1)\n",
    "    causal_ordering2 = get_full_ordering(DAGnx2)\n",
    "    mediated_dag_stuff = (all_data2, DAGnx2, var_names2, causal_ordering2, var_types)\n",
    "    \n",
    "    DAGnx3.add_edges_from([('X1', 'Y'), ('X1', 'X2'), ('X1', 'X3'), ('X2', 'Y'), ('Y', 'X3')])\n",
    "    DAGnx3 = reorder_dag(dag=DAGnx3)  # topologically sorted dag\n",
    "    var_names3 = list(DAGnx3.nodes())  # topologically ordered list of variables\n",
    "    all_data3 = np.stack([all_data_dict[key] for key in var_names3], axis=1)\n",
    "    causal_ordering3 = get_full_ordering(DAGnx3)\n",
    "    correct_dag_stuff =  (all_data3, DAGnx3, var_names3, causal_ordering3, var_types)\n",
    "\n",
    "    return ex_dag_stuff, mediated_dag_stuff, correct_dag_stuff, Y0, Y1\n",
    "\n",
    "d=1\n",
    "_, _, _, Y0, Y1 = generate_data(N=1000000, d=d)\n",
    "ATE = (Y1 - Y0).mean(0)  \n",
    "ex_dag_stuff, mediated_dag_stuff, correct_dag_stuff, Y0, Y1 = generate_data(N=sample_size, d=d)\n",
    "\n",
    "all_data1, DAGnx1, var_names1, causal_ordering1, var_types1 = ex_dag_stuff\n",
    "all_data2, DAGnx2, var_names2, causal_ordering2, var_types2 = mediated_dag_stuff\n",
    "all_data3, DAGnx3, var_names3, causal_ordering3, var_types3 = correct_dag_stuff\n",
    "\n",
    "print(var_names1, 'ATE of X1 on Y:', ATE)\n",
    "print(all_data1.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X1', 'X2', 'X3', 'Y'] ATE of X1 on Y: [1.12]\n",
      "(100000, 4, 1)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "7277cb8c-d1a1-44dc-a567-f0a7d2803887",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T13:39:19.654643Z",
     "start_time": "2024-10-01T13:39:19.652825Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "7865de21-8b33-4b80-b3df-41ddedac0119",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T13:39:19.868240Z",
     "start_time": "2024-10-01T13:39:19.655731Z"
    }
   },
   "source": [
    "print('Incorrect DAG 1:')\n",
    "nx.draw_planar(\n",
    "    DAGnx1,\n",
    "    with_labels=True,\n",
    "    node_size=1000,\n",
    "    node_color=\"#ffff8f\",\n",
    "    width=0.5,\n",
    "    font_size=10,\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "print('Incorrect DAG 2:')\n",
    "nx.draw_planar(\n",
    "    DAGnx2,\n",
    "    with_labels=True,\n",
    "    node_size=1000,\n",
    "    node_color=\"#ffff8f\",\n",
    "    width=0.5,\n",
    "    font_size=10,\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "print('Correct DAG:')\n",
    "nx.draw_planar(\n",
    "    DAGnx3,\n",
    "    with_labels=True,\n",
    "    node_size=1000,\n",
    "    node_color=\"#ffff8f\",\n",
    "    width=0.5,\n",
    "    font_size=10,\n",
    ")\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect DAG 1:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect DAG 2:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct DAG:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "4e6dea20",
   "metadata": {},
   "source": [
    "We run the model with the same data each time (although the column ordering of the data is different in each case, according to the assumed underlying DAG), and provide fit statistics as well as estimated causal links."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8541753a",
   "metadata": {},
   "source": [
    "### Incorrect DAG 1 (fully exogenous)"
   ]
  },
  {
   "cell_type": "code",
   "id": "8ab383e3",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-10-01T13:51:12.008782Z",
     "start_time": "2024-10-01T13:39:19.870349Z"
    }
   },
   "source": [
    "indices = np.arange(0, len(all_data1))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "val_inds = indices[:int(validation_fraction*len(indices))]\n",
    "train_inds = indices[int(validation_fraction*len(indices)):]\n",
    "train_data = all_data1[train_inds]\n",
    "val_data = all_data1[val_inds]\n",
    "train_data, val_data = torch.from_numpy(train_data).float(),  torch.from_numpy(val_data).float()\n",
    "\n",
    "input_dim = all_data1.shape[2]\n",
    "\n",
    "model1 = CaT(input_dim=input_dim,\n",
    "                    dropout_rate=dropout_rate,\n",
    "                    head_size=head_size,\n",
    "                    num_heads=num_heads,\n",
    "                    ff_n_embed=ff_n_embed,\n",
    "                    embed_dim= embed_dim,\n",
    "                    dag=DAGnx1,\n",
    "                    causal_ordering=causal_ordering1,\n",
    "                    n_layers=n_layers,\n",
    "                    device=device,\n",
    "                    var_types=var_types1, activation_function='Swish'\n",
    "                    ).to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model1.parameters(), lr=learning_rate)\n",
    "\n",
    "def get_batch(train_data, val_data, split, device, batch_size):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(0, len(data), (batch_size,))\n",
    "    x = data[ix]\n",
    "    return x.to(device)\n",
    "\n",
    "all_var_losses = {}\n",
    "for iter_ in range(0, max_iters):\n",
    "    # train and update the model\n",
    "    model1.train()\n",
    "\n",
    "    xb = get_batch(train_data=train_data, val_data=val_data, split='train', device=device, batch_size=batch_size)\n",
    "    xb_mod = torch.clone(xb.detach())\n",
    "    X, loss, loss_dict = model1(X=xb, targets=xb_mod\n",
    "                                )\n",
    "\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "    if iter_ % eval_interval == 0:  # evaluate the loss (no gradients)\n",
    "        for key in loss_dict.keys():\n",
    "            if key not in all_var_losses.keys():\n",
    "                all_var_losses[key] = []\n",
    "            all_var_losses[key].append(loss_dict[key])\n",
    "\n",
    "        model1.eval()\n",
    "        eval_loss = {}\n",
    "        for split in ['train', 'val']:\n",
    "            losses = torch.zeros(eval_iters)\n",
    "            for k in range(eval_iters):\n",
    "\n",
    "                xb = get_batch(train_data=train_data, val_data=val_data, split=split, device=device,\n",
    "                               batch_size=batch_size)\n",
    "                xb_mod = torch.clone(xb.detach())\n",
    "                X, loss, loss_dict = model1(X=xb, targets=xb_mod)\n",
    "                losses[k] = loss.item()\n",
    "            eval_loss[split] = losses.mean()\n",
    "        model1.train()\n",
    "        print(f\"step {iter_} of {max_iters}: train_loss {eval_loss['train']:.4f}, val loss {eval_loss['val']:.4f}\")\n",
    " "
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 of 50000: train_loss 1.1714, val loss 1.1955\n",
      "step 100 of 50000: train_loss 0.6982, val loss 0.6951\n",
      "step 200 of 50000: train_loss 0.6808, val loss 0.6595\n",
      "step 300 of 50000: train_loss 0.6758, val loss 0.6760\n",
      "step 400 of 50000: train_loss 0.6559, val loss 0.6740\n",
      "step 500 of 50000: train_loss 0.6756, val loss 0.6862\n",
      "step 600 of 50000: train_loss 0.6968, val loss 0.6991\n",
      "step 700 of 50000: train_loss 0.6766, val loss 0.6632\n",
      "step 800 of 50000: train_loss 0.6736, val loss 0.6954\n",
      "step 900 of 50000: train_loss 0.6590, val loss 0.6811\n",
      "step 1000 of 50000: train_loss 0.6763, val loss 0.6899\n",
      "step 1100 of 50000: train_loss 0.6772, val loss 0.6599\n",
      "step 1200 of 50000: train_loss 0.7002, val loss 0.7091\n",
      "step 1300 of 50000: train_loss 0.6558, val loss 0.6804\n",
      "step 1400 of 50000: train_loss 0.6739, val loss 0.6870\n",
      "step 1500 of 50000: train_loss 0.6747, val loss 0.7085\n",
      "step 1600 of 50000: train_loss 0.6578, val loss 0.6745\n",
      "step 1700 of 50000: train_loss 0.6603, val loss 0.6701\n",
      "step 1800 of 50000: train_loss 0.6743, val loss 0.6853\n",
      "step 1900 of 50000: train_loss 0.6658, val loss 0.6637\n",
      "step 2000 of 50000: train_loss 0.6730, val loss 0.6792\n",
      "step 2100 of 50000: train_loss 0.6871, val loss 0.6911\n",
      "step 2200 of 50000: train_loss 0.6775, val loss 0.7023\n",
      "step 2300 of 50000: train_loss 0.6787, val loss 0.6831\n",
      "step 2400 of 50000: train_loss 0.6901, val loss 0.6919\n",
      "step 2500 of 50000: train_loss 0.6712, val loss 0.6839\n",
      "step 2600 of 50000: train_loss 0.6611, val loss 0.6734\n",
      "step 2700 of 50000: train_loss 0.6772, val loss 0.6839\n",
      "step 2800 of 50000: train_loss 0.6648, val loss 0.6660\n",
      "step 2900 of 50000: train_loss 0.6731, val loss 0.6716\n",
      "step 3000 of 50000: train_loss 0.6930, val loss 0.6691\n",
      "step 3100 of 50000: train_loss 0.6642, val loss 0.6736\n",
      "step 3200 of 50000: train_loss 0.6665, val loss 0.6950\n",
      "step 3300 of 50000: train_loss 0.6743, val loss 0.6806\n",
      "step 3400 of 50000: train_loss 0.6719, val loss 0.6956\n",
      "step 3500 of 50000: train_loss 0.6675, val loss 0.6793\n",
      "step 3600 of 50000: train_loss 0.6707, val loss 0.7021\n",
      "step 3700 of 50000: train_loss 0.6790, val loss 0.6565\n",
      "step 3800 of 50000: train_loss 0.6600, val loss 0.6833\n",
      "step 3900 of 50000: train_loss 0.6838, val loss 0.6768\n",
      "step 4000 of 50000: train_loss 0.6907, val loss 0.6914\n",
      "step 4100 of 50000: train_loss 0.6633, val loss 0.6783\n",
      "step 4200 of 50000: train_loss 0.6686, val loss 0.6867\n",
      "step 4300 of 50000: train_loss 0.6834, val loss 0.6759\n",
      "step 4400 of 50000: train_loss 0.6731, val loss 0.7052\n",
      "step 4500 of 50000: train_loss 0.6803, val loss 0.6849\n",
      "step 4600 of 50000: train_loss 0.6655, val loss 0.6967\n",
      "step 4700 of 50000: train_loss 0.6667, val loss 0.6638\n",
      "step 4800 of 50000: train_loss 0.6591, val loss 0.6863\n",
      "step 4900 of 50000: train_loss 0.6729, val loss 0.6729\n",
      "step 5000 of 50000: train_loss 0.6550, val loss 0.6943\n",
      "step 5100 of 50000: train_loss 0.6788, val loss 0.7115\n",
      "step 5200 of 50000: train_loss 0.6770, val loss 0.6624\n",
      "step 5300 of 50000: train_loss 0.6652, val loss 0.6755\n",
      "step 5400 of 50000: train_loss 0.6617, val loss 0.6651\n",
      "step 5500 of 50000: train_loss 0.6751, val loss 0.6692\n",
      "step 5600 of 50000: train_loss 0.6741, val loss 0.6773\n",
      "step 5700 of 50000: train_loss 0.6614, val loss 0.6788\n",
      "step 5800 of 50000: train_loss 0.6672, val loss 0.6772\n",
      "step 5900 of 50000: train_loss 0.6574, val loss 0.6834\n",
      "step 6000 of 50000: train_loss 0.6595, val loss 0.6652\n",
      "step 6100 of 50000: train_loss 0.7021, val loss 0.6991\n",
      "step 6200 of 50000: train_loss 0.7021, val loss 0.6851\n",
      "step 6300 of 50000: train_loss 0.6674, val loss 0.6735\n",
      "step 6400 of 50000: train_loss 0.6535, val loss 0.6764\n",
      "step 6500 of 50000: train_loss 0.6724, val loss 0.6741\n",
      "step 6600 of 50000: train_loss 0.6747, val loss 0.6783\n",
      "step 6700 of 50000: train_loss 0.6990, val loss 0.6998\n",
      "step 6800 of 50000: train_loss 0.6603, val loss 0.6602\n",
      "step 6900 of 50000: train_loss 0.6757, val loss 0.6868\n",
      "step 7000 of 50000: train_loss 0.6852, val loss 0.7018\n",
      "step 7100 of 50000: train_loss 0.6879, val loss 0.7056\n",
      "step 7200 of 50000: train_loss 0.6746, val loss 0.6993\n",
      "step 7300 of 50000: train_loss 0.6785, val loss 0.6750\n",
      "step 7400 of 50000: train_loss 0.6664, val loss 0.6806\n",
      "step 7500 of 50000: train_loss 0.6760, val loss 0.6757\n",
      "step 7600 of 50000: train_loss 0.6688, val loss 0.6843\n",
      "step 7700 of 50000: train_loss 0.6717, val loss 0.6829\n",
      "step 7800 of 50000: train_loss 0.6497, val loss 0.6943\n",
      "step 7900 of 50000: train_loss 0.6738, val loss 0.6743\n",
      "step 8000 of 50000: train_loss 0.6658, val loss 0.6844\n",
      "step 8100 of 50000: train_loss 0.6752, val loss 0.6796\n",
      "step 8200 of 50000: train_loss 0.6604, val loss 0.6486\n",
      "step 8300 of 50000: train_loss 0.6713, val loss 0.6901\n",
      "step 8400 of 50000: train_loss 0.6630, val loss 0.6773\n",
      "step 8500 of 50000: train_loss 0.6756, val loss 0.6888\n",
      "step 8600 of 50000: train_loss 0.6774, val loss 0.6977\n",
      "step 8700 of 50000: train_loss 0.6704, val loss 0.6583\n",
      "step 8800 of 50000: train_loss 0.6584, val loss 0.6823\n",
      "step 8900 of 50000: train_loss 0.6681, val loss 0.6753\n",
      "step 9000 of 50000: train_loss 0.6716, val loss 0.6795\n",
      "step 9100 of 50000: train_loss 0.6839, val loss 0.6828\n",
      "step 9200 of 50000: train_loss 0.6713, val loss 0.6782\n",
      "step 9300 of 50000: train_loss 0.6638, val loss 0.6883\n",
      "step 9400 of 50000: train_loss 0.6721, val loss 0.6814\n",
      "step 9500 of 50000: train_loss 0.6597, val loss 0.6768\n",
      "step 9600 of 50000: train_loss 0.6793, val loss 0.6706\n",
      "step 9700 of 50000: train_loss 0.6863, val loss 0.6998\n",
      "step 9800 of 50000: train_loss 0.6546, val loss 0.6764\n",
      "step 9900 of 50000: train_loss 0.6817, val loss 0.6766\n",
      "step 10000 of 50000: train_loss 0.6593, val loss 0.6860\n",
      "step 10100 of 50000: train_loss 0.6633, val loss 0.6830\n",
      "step 10200 of 50000: train_loss 0.6836, val loss 0.6694\n",
      "step 10300 of 50000: train_loss 0.6834, val loss 0.6936\n",
      "step 10400 of 50000: train_loss 0.6511, val loss 0.6801\n",
      "step 10500 of 50000: train_loss 0.6748, val loss 0.6894\n",
      "step 10600 of 50000: train_loss 0.6796, val loss 0.6945\n",
      "step 10700 of 50000: train_loss 0.6403, val loss 0.6735\n",
      "step 10800 of 50000: train_loss 0.7192, val loss 0.7423\n",
      "step 10900 of 50000: train_loss 0.6711, val loss 0.6954\n",
      "step 11000 of 50000: train_loss 0.6461, val loss 0.6724\n",
      "step 11100 of 50000: train_loss 0.6613, val loss 0.6872\n",
      "step 11200 of 50000: train_loss 0.6690, val loss 0.6794\n",
      "step 11300 of 50000: train_loss 0.6699, val loss 0.6754\n",
      "step 11400 of 50000: train_loss 0.6545, val loss 0.6715\n",
      "step 11500 of 50000: train_loss 0.6623, val loss 0.6832\n",
      "step 11600 of 50000: train_loss 0.6511, val loss 0.6729\n",
      "step 11700 of 50000: train_loss 0.6634, val loss 0.6856\n",
      "step 11800 of 50000: train_loss 0.6709, val loss 0.6732\n",
      "step 11900 of 50000: train_loss 0.6632, val loss 0.6887\n",
      "step 12000 of 50000: train_loss 0.6716, val loss 0.6709\n",
      "step 12100 of 50000: train_loss 0.6836, val loss 0.6861\n",
      "step 12200 of 50000: train_loss 0.6681, val loss 0.6706\n",
      "step 12300 of 50000: train_loss 0.6741, val loss 0.6702\n",
      "step 12400 of 50000: train_loss 0.6664, val loss 0.6868\n",
      "step 12500 of 50000: train_loss 0.6749, val loss 0.7149\n",
      "step 12600 of 50000: train_loss 0.6722, val loss 0.6809\n",
      "step 12700 of 50000: train_loss 0.6735, val loss 0.6816\n",
      "step 12800 of 50000: train_loss 0.6689, val loss 0.6633\n",
      "step 12900 of 50000: train_loss 0.6862, val loss 0.6957\n",
      "step 13000 of 50000: train_loss 0.6626, val loss 0.6631\n",
      "step 13100 of 50000: train_loss 0.6644, val loss 0.6824\n",
      "step 13200 of 50000: train_loss 0.6683, val loss 0.6899\n",
      "step 13300 of 50000: train_loss 0.6625, val loss 0.6877\n",
      "step 13400 of 50000: train_loss 0.6913, val loss 0.7070\n",
      "step 13500 of 50000: train_loss 0.6910, val loss 0.6714\n",
      "step 13600 of 50000: train_loss 0.6787, val loss 0.6914\n",
      "step 13700 of 50000: train_loss 0.6816, val loss 0.6912\n",
      "step 13800 of 50000: train_loss 0.6667, val loss 0.6781\n",
      "step 13900 of 50000: train_loss 0.6648, val loss 0.6751\n",
      "step 14000 of 50000: train_loss 0.6870, val loss 0.6583\n",
      "step 14100 of 50000: train_loss 0.6643, val loss 0.6715\n",
      "step 14200 of 50000: train_loss 0.6755, val loss 0.6773\n",
      "step 14300 of 50000: train_loss 0.6787, val loss 0.6808\n",
      "step 14400 of 50000: train_loss 0.6702, val loss 0.6823\n",
      "step 14500 of 50000: train_loss 0.6771, val loss 0.6840\n",
      "step 14600 of 50000: train_loss 0.6894, val loss 0.6964\n",
      "step 14700 of 50000: train_loss 0.6702, val loss 0.6750\n",
      "step 14800 of 50000: train_loss 0.6824, val loss 0.6999\n",
      "step 14900 of 50000: train_loss 0.6506, val loss 0.6611\n",
      "step 15000 of 50000: train_loss 0.6723, val loss 0.6804\n",
      "step 15100 of 50000: train_loss 0.6716, val loss 0.6664\n",
      "step 15200 of 50000: train_loss 0.6569, val loss 0.6900\n",
      "step 15300 of 50000: train_loss 0.6714, val loss 0.6908\n",
      "step 15400 of 50000: train_loss 0.6761, val loss 0.6700\n",
      "step 15500 of 50000: train_loss 0.6598, val loss 0.6722\n",
      "step 15600 of 50000: train_loss 0.6646, val loss 0.6867\n",
      "step 15700 of 50000: train_loss 0.6621, val loss 0.6806\n",
      "step 15800 of 50000: train_loss 0.6663, val loss 0.6744\n",
      "step 15900 of 50000: train_loss 0.6601, val loss 0.6814\n",
      "step 16000 of 50000: train_loss 0.6739, val loss 0.6973\n",
      "step 16100 of 50000: train_loss 0.6760, val loss 0.6909\n",
      "step 16200 of 50000: train_loss 0.6768, val loss 0.6939\n",
      "step 16300 of 50000: train_loss 0.6543, val loss 0.6691\n",
      "step 16400 of 50000: train_loss 0.6760, val loss 0.6678\n",
      "step 16500 of 50000: train_loss 0.6708, val loss 0.6988\n",
      "step 16600 of 50000: train_loss 0.6756, val loss 0.6745\n",
      "step 16700 of 50000: train_loss 0.6730, val loss 0.6703\n",
      "step 16800 of 50000: train_loss 0.6648, val loss 0.6645\n",
      "step 16900 of 50000: train_loss 0.6457, val loss 0.6728\n",
      "step 17000 of 50000: train_loss 0.6768, val loss 0.6897\n",
      "step 17100 of 50000: train_loss 0.6714, val loss 0.7017\n",
      "step 17200 of 50000: train_loss 0.6786, val loss 0.6997\n",
      "step 17300 of 50000: train_loss 0.6567, val loss 0.6693\n",
      "step 17400 of 50000: train_loss 0.6695, val loss 0.6806\n",
      "step 17500 of 50000: train_loss 0.6595, val loss 0.6780\n",
      "step 17600 of 50000: train_loss 0.6658, val loss 0.6845\n",
      "step 17700 of 50000: train_loss 0.6836, val loss 0.6833\n",
      "step 17800 of 50000: train_loss 0.6849, val loss 0.6625\n",
      "step 17900 of 50000: train_loss 0.6876, val loss 0.6810\n",
      "step 18000 of 50000: train_loss 0.6768, val loss 0.6824\n",
      "step 18100 of 50000: train_loss 0.6689, val loss 0.6653\n",
      "step 18200 of 50000: train_loss 0.6787, val loss 0.6960\n",
      "step 18300 of 50000: train_loss 0.6821, val loss 0.6746\n",
      "step 18400 of 50000: train_loss 0.6691, val loss 0.6743\n",
      "step 18500 of 50000: train_loss 0.6875, val loss 0.6826\n",
      "step 18600 of 50000: train_loss 0.6571, val loss 0.6754\n",
      "step 18700 of 50000: train_loss 0.6778, val loss 0.6909\n",
      "step 18800 of 50000: train_loss 0.6765, val loss 0.6952\n",
      "step 18900 of 50000: train_loss 0.6669, val loss 0.6939\n",
      "step 19000 of 50000: train_loss 0.6574, val loss 0.6907\n",
      "step 19100 of 50000: train_loss 0.6636, val loss 0.6762\n",
      "step 19200 of 50000: train_loss 0.6811, val loss 0.6911\n",
      "step 19300 of 50000: train_loss 0.6686, val loss 0.6769\n",
      "step 19400 of 50000: train_loss 0.6809, val loss 0.6733\n",
      "step 19500 of 50000: train_loss 0.6719, val loss 0.6809\n",
      "step 19600 of 50000: train_loss 0.6665, val loss 0.6870\n",
      "step 19700 of 50000: train_loss 0.6545, val loss 0.6784\n",
      "step 19800 of 50000: train_loss 0.6657, val loss 0.6719\n",
      "step 19900 of 50000: train_loss 0.6641, val loss 0.6770\n",
      "step 20000 of 50000: train_loss 0.6773, val loss 0.6668\n",
      "step 20100 of 50000: train_loss 0.6620, val loss 0.6854\n",
      "step 20200 of 50000: train_loss 0.6716, val loss 0.6817\n",
      "step 20300 of 50000: train_loss 0.6763, val loss 0.6596\n",
      "step 20400 of 50000: train_loss 0.6786, val loss 0.6912\n",
      "step 20500 of 50000: train_loss 0.6647, val loss 0.6664\n",
      "step 20600 of 50000: train_loss 0.6706, val loss 0.6726\n",
      "step 20700 of 50000: train_loss 0.6721, val loss 0.6872\n",
      "step 20800 of 50000: train_loss 0.6550, val loss 0.6824\n",
      "step 20900 of 50000: train_loss 0.6518, val loss 0.6831\n",
      "step 21000 of 50000: train_loss 0.6904, val loss 0.6589\n",
      "step 21100 of 50000: train_loss 0.6593, val loss 0.6726\n",
      "step 21200 of 50000: train_loss 0.6638, val loss 0.6857\n",
      "step 21300 of 50000: train_loss 0.6799, val loss 0.6776\n",
      "step 21400 of 50000: train_loss 0.6699, val loss 0.6826\n",
      "step 21500 of 50000: train_loss 0.6645, val loss 0.6836\n",
      "step 21600 of 50000: train_loss 0.6521, val loss 0.6636\n",
      "step 21700 of 50000: train_loss 0.6687, val loss 0.6950\n",
      "step 21800 of 50000: train_loss 0.6807, val loss 0.7037\n",
      "step 21900 of 50000: train_loss 0.6739, val loss 0.6977\n",
      "step 22000 of 50000: train_loss 0.6695, val loss 0.6638\n",
      "step 22100 of 50000: train_loss 0.6555, val loss 0.6798\n",
      "step 22200 of 50000: train_loss 0.6700, val loss 0.6894\n",
      "step 22300 of 50000: train_loss 0.6639, val loss 0.6773\n",
      "step 22400 of 50000: train_loss 0.6721, val loss 0.6893\n",
      "step 22500 of 50000: train_loss 0.6703, val loss 0.6808\n",
      "step 22600 of 50000: train_loss 0.6552, val loss 0.6894\n",
      "step 22700 of 50000: train_loss 0.6787, val loss 0.6952\n",
      "step 22800 of 50000: train_loss 0.6757, val loss 0.6811\n",
      "step 22900 of 50000: train_loss 0.6668, val loss 0.6590\n",
      "step 23000 of 50000: train_loss 0.6824, val loss 0.7072\n",
      "step 23100 of 50000: train_loss 0.6674, val loss 0.6683\n",
      "step 23200 of 50000: train_loss 0.6757, val loss 0.6648\n",
      "step 23300 of 50000: train_loss 0.6664, val loss 0.6759\n",
      "step 23400 of 50000: train_loss 0.6702, val loss 0.6805\n",
      "step 23500 of 50000: train_loss 0.6710, val loss 0.6704\n",
      "step 23600 of 50000: train_loss 0.6737, val loss 0.6761\n",
      "step 23700 of 50000: train_loss 0.6620, val loss 0.6704\n",
      "step 23800 of 50000: train_loss 0.6571, val loss 0.6832\n",
      "step 23900 of 50000: train_loss 0.6645, val loss 0.6766\n",
      "step 24000 of 50000: train_loss 0.6683, val loss 0.7019\n",
      "step 24100 of 50000: train_loss 0.6622, val loss 0.6666\n",
      "step 24200 of 50000: train_loss 0.6664, val loss 0.6628\n",
      "step 24300 of 50000: train_loss 0.6701, val loss 0.7001\n",
      "step 24400 of 50000: train_loss 0.6539, val loss 0.6692\n",
      "step 24500 of 50000: train_loss 0.6816, val loss 0.6791\n",
      "step 24600 of 50000: train_loss 0.6717, val loss 0.6659\n",
      "step 24700 of 50000: train_loss 0.6735, val loss 0.6787\n",
      "step 24800 of 50000: train_loss 0.6687, val loss 0.6676\n",
      "step 24900 of 50000: train_loss 0.6606, val loss 0.6877\n",
      "step 25000 of 50000: train_loss 0.6821, val loss 0.6926\n",
      "step 25100 of 50000: train_loss 0.6742, val loss 0.6846\n",
      "step 25200 of 50000: train_loss 0.6627, val loss 0.6818\n",
      "step 25300 of 50000: train_loss 0.6811, val loss 0.6682\n",
      "step 25400 of 50000: train_loss 0.6567, val loss 0.6715\n",
      "step 25500 of 50000: train_loss 0.6666, val loss 0.6861\n",
      "step 25600 of 50000: train_loss 0.6806, val loss 0.6739\n",
      "step 25700 of 50000: train_loss 0.6523, val loss 0.6829\n",
      "step 25800 of 50000: train_loss 0.6599, val loss 0.6870\n",
      "step 25900 of 50000: train_loss 0.6791, val loss 0.6769\n",
      "step 26000 of 50000: train_loss 0.6684, val loss 0.6711\n",
      "step 26100 of 50000: train_loss 0.6577, val loss 0.6793\n",
      "step 26200 of 50000: train_loss 0.6735, val loss 0.6935\n",
      "step 26300 of 50000: train_loss 0.6715, val loss 0.6835\n",
      "step 26400 of 50000: train_loss 0.6649, val loss 0.6687\n",
      "step 26500 of 50000: train_loss 0.6808, val loss 0.6695\n",
      "step 26600 of 50000: train_loss 0.6636, val loss 0.6949\n",
      "step 26700 of 50000: train_loss 0.6688, val loss 0.6602\n",
      "step 26800 of 50000: train_loss 0.6712, val loss 0.6810\n",
      "step 26900 of 50000: train_loss 0.6907, val loss 0.6793\n",
      "step 27000 of 50000: train_loss 0.6752, val loss 0.6689\n",
      "step 27100 of 50000: train_loss 0.6641, val loss 0.6913\n",
      "step 27200 of 50000: train_loss 0.6554, val loss 0.6820\n",
      "step 27300 of 50000: train_loss 0.6619, val loss 0.6655\n",
      "step 27400 of 50000: train_loss 0.6587, val loss 0.6759\n",
      "step 27500 of 50000: train_loss 0.6601, val loss 0.6800\n",
      "step 27600 of 50000: train_loss 0.6730, val loss 0.6671\n",
      "step 27700 of 50000: train_loss 0.6711, val loss 0.6600\n",
      "step 27800 of 50000: train_loss 0.6678, val loss 0.6714\n",
      "step 27900 of 50000: train_loss 0.6707, val loss 0.6847\n",
      "step 28000 of 50000: train_loss 0.6706, val loss 0.6851\n",
      "step 28100 of 50000: train_loss 0.6667, val loss 0.6863\n",
      "step 28200 of 50000: train_loss 0.6744, val loss 0.6881\n",
      "step 28300 of 50000: train_loss 0.6735, val loss 0.6889\n",
      "step 28400 of 50000: train_loss 0.6682, val loss 0.6894\n",
      "step 28500 of 50000: train_loss 0.6767, val loss 0.6863\n",
      "step 28600 of 50000: train_loss 0.6781, val loss 0.6933\n",
      "step 28700 of 50000: train_loss 0.6590, val loss 0.6803\n",
      "step 28800 of 50000: train_loss 0.6717, val loss 0.6744\n",
      "step 28900 of 50000: train_loss 0.6728, val loss 0.6902\n",
      "step 29000 of 50000: train_loss 0.6717, val loss 0.6875\n",
      "step 29100 of 50000: train_loss 0.6658, val loss 0.6823\n",
      "step 29200 of 50000: train_loss 0.6656, val loss 0.6653\n",
      "step 29300 of 50000: train_loss 0.6633, val loss 0.6615\n",
      "step 29400 of 50000: train_loss 0.6475, val loss 0.6884\n",
      "step 29500 of 50000: train_loss 0.6746, val loss 0.6786\n",
      "step 29600 of 50000: train_loss 0.6712, val loss 0.6775\n",
      "step 29700 of 50000: train_loss 0.6564, val loss 0.6812\n",
      "step 29800 of 50000: train_loss 0.6584, val loss 0.6833\n",
      "step 29900 of 50000: train_loss 0.6510, val loss 0.6691\n",
      "step 30000 of 50000: train_loss 0.6786, val loss 0.6842\n",
      "step 30100 of 50000: train_loss 0.6666, val loss 0.6757\n",
      "step 30200 of 50000: train_loss 0.6616, val loss 0.6908\n",
      "step 30300 of 50000: train_loss 0.6895, val loss 0.6871\n",
      "step 30400 of 50000: train_loss 0.6548, val loss 0.6818\n",
      "step 30500 of 50000: train_loss 0.6632, val loss 0.6778\n",
      "step 30600 of 50000: train_loss 0.6788, val loss 0.6955\n",
      "step 30700 of 50000: train_loss 0.6719, val loss 0.6708\n",
      "step 30800 of 50000: train_loss 0.6750, val loss 0.6873\n",
      "step 30900 of 50000: train_loss 0.6609, val loss 0.6830\n",
      "step 31000 of 50000: train_loss 0.6613, val loss 0.6944\n",
      "step 31100 of 50000: train_loss 0.6621, val loss 0.6845\n",
      "step 31200 of 50000: train_loss 0.6499, val loss 0.6791\n",
      "step 31300 of 50000: train_loss 0.6566, val loss 0.6684\n",
      "step 31400 of 50000: train_loss 0.6745, val loss 0.6944\n",
      "step 31500 of 50000: train_loss 0.6654, val loss 0.6688\n",
      "step 31600 of 50000: train_loss 0.6708, val loss 0.6740\n",
      "step 31700 of 50000: train_loss 0.6630, val loss 0.6699\n",
      "step 31800 of 50000: train_loss 0.6616, val loss 0.6795\n",
      "step 31900 of 50000: train_loss 0.6765, val loss 0.6821\n",
      "step 32000 of 50000: train_loss 0.6478, val loss 0.6752\n",
      "step 32100 of 50000: train_loss 0.6576, val loss 0.6868\n",
      "step 32200 of 50000: train_loss 0.6655, val loss 0.6785\n",
      "step 32300 of 50000: train_loss 0.6754, val loss 0.6811\n",
      "step 32400 of 50000: train_loss 0.6592, val loss 0.6804\n",
      "step 32500 of 50000: train_loss 0.6790, val loss 0.6815\n",
      "step 32600 of 50000: train_loss 0.6611, val loss 0.6695\n",
      "step 32700 of 50000: train_loss 0.6745, val loss 0.6613\n",
      "step 32800 of 50000: train_loss 0.6582, val loss 0.6595\n",
      "step 32900 of 50000: train_loss 0.6690, val loss 0.6832\n",
      "step 33000 of 50000: train_loss 0.6671, val loss 0.6842\n",
      "step 33100 of 50000: train_loss 0.6472, val loss 0.6870\n",
      "step 33200 of 50000: train_loss 0.6727, val loss 0.6921\n",
      "step 33300 of 50000: train_loss 0.6626, val loss 0.6766\n",
      "step 33400 of 50000: train_loss 0.6665, val loss 0.6802\n",
      "step 33500 of 50000: train_loss 0.6633, val loss 0.6985\n",
      "step 33600 of 50000: train_loss 0.6726, val loss 0.6749\n",
      "step 33700 of 50000: train_loss 0.6752, val loss 0.6521\n",
      "step 33800 of 50000: train_loss 0.6593, val loss 0.6878\n",
      "step 33900 of 50000: train_loss 0.6754, val loss 0.6612\n",
      "step 34000 of 50000: train_loss 0.6739, val loss 0.6800\n",
      "step 34100 of 50000: train_loss 0.6662, val loss 0.6916\n",
      "step 34200 of 50000: train_loss 0.6615, val loss 0.6678\n",
      "step 34300 of 50000: train_loss 0.6793, val loss 0.6790\n",
      "step 34400 of 50000: train_loss 0.6622, val loss 0.6757\n",
      "step 34500 of 50000: train_loss 0.6833, val loss 0.6781\n",
      "step 34600 of 50000: train_loss 0.6836, val loss 0.6757\n",
      "step 34700 of 50000: train_loss 0.6688, val loss 0.6802\n",
      "step 34800 of 50000: train_loss 0.6771, val loss 0.6693\n",
      "step 34900 of 50000: train_loss 0.6767, val loss 0.6914\n",
      "step 35000 of 50000: train_loss 0.6674, val loss 0.6777\n",
      "step 35100 of 50000: train_loss 0.6797, val loss 0.6631\n",
      "step 35200 of 50000: train_loss 0.6620, val loss 0.6839\n",
      "step 35300 of 50000: train_loss 0.6859, val loss 0.6781\n",
      "step 35400 of 50000: train_loss 0.6662, val loss 0.6841\n",
      "step 35500 of 50000: train_loss 0.6687, val loss 0.6871\n",
      "step 35600 of 50000: train_loss 0.6740, val loss 0.6974\n",
      "step 35700 of 50000: train_loss 0.6760, val loss 0.6694\n",
      "step 35800 of 50000: train_loss 0.6854, val loss 0.6884\n",
      "step 35900 of 50000: train_loss 0.6574, val loss 0.6831\n",
      "step 36000 of 50000: train_loss 0.6687, val loss 0.6800\n",
      "step 36100 of 50000: train_loss 0.6600, val loss 0.6708\n",
      "step 36200 of 50000: train_loss 0.6613, val loss 0.6810\n",
      "step 36300 of 50000: train_loss 0.6714, val loss 0.6760\n",
      "step 36400 of 50000: train_loss 0.6676, val loss 0.6755\n",
      "step 36500 of 50000: train_loss 0.6834, val loss 0.6594\n",
      "step 36600 of 50000: train_loss 0.6542, val loss 0.6830\n",
      "step 36700 of 50000: train_loss 0.6684, val loss 0.6673\n",
      "step 36800 of 50000: train_loss 0.6794, val loss 0.6916\n",
      "step 36900 of 50000: train_loss 0.6662, val loss 0.6606\n",
      "step 37000 of 50000: train_loss 0.6891, val loss 0.6931\n",
      "step 37100 of 50000: train_loss 0.6715, val loss 0.6618\n",
      "step 37200 of 50000: train_loss 0.6691, val loss 0.6686\n",
      "step 37300 of 50000: train_loss 0.6512, val loss 0.6752\n",
      "step 37400 of 50000: train_loss 0.6600, val loss 0.6783\n",
      "step 37500 of 50000: train_loss 0.6777, val loss 0.6856\n",
      "step 37600 of 50000: train_loss 0.6874, val loss 0.6898\n",
      "step 37700 of 50000: train_loss 0.6591, val loss 0.6764\n",
      "step 37800 of 50000: train_loss 0.6760, val loss 0.6748\n",
      "step 37900 of 50000: train_loss 0.6726, val loss 0.6525\n",
      "step 38000 of 50000: train_loss 0.6725, val loss 0.6905\n",
      "step 38100 of 50000: train_loss 0.6731, val loss 0.6595\n",
      "step 38200 of 50000: train_loss 0.6790, val loss 0.6792\n",
      "step 38300 of 50000: train_loss 0.6567, val loss 0.6485\n",
      "step 38400 of 50000: train_loss 0.6676, val loss 0.6911\n",
      "step 38500 of 50000: train_loss 0.6519, val loss 0.6849\n",
      "step 38600 of 50000: train_loss 0.6686, val loss 0.6787\n",
      "step 38700 of 50000: train_loss 0.6723, val loss 0.6568\n",
      "step 38800 of 50000: train_loss 0.6582, val loss 0.6860\n",
      "step 38900 of 50000: train_loss 0.6678, val loss 0.6745\n",
      "step 39000 of 50000: train_loss 0.6819, val loss 0.6737\n",
      "step 39100 of 50000: train_loss 0.6741, val loss 0.6868\n",
      "step 39200 of 50000: train_loss 0.6847, val loss 0.6946\n",
      "step 39300 of 50000: train_loss 0.6729, val loss 0.6908\n",
      "step 39400 of 50000: train_loss 0.6719, val loss 0.6833\n",
      "step 39500 of 50000: train_loss 0.6742, val loss 0.6865\n",
      "step 39600 of 50000: train_loss 0.6652, val loss 0.6836\n",
      "step 39700 of 50000: train_loss 0.6797, val loss 0.6798\n",
      "step 39800 of 50000: train_loss 0.6636, val loss 0.6896\n",
      "step 39900 of 50000: train_loss 0.6593, val loss 0.6729\n",
      "step 40000 of 50000: train_loss 0.6710, val loss 0.6730\n",
      "step 40100 of 50000: train_loss 0.6612, val loss 0.6849\n",
      "step 40200 of 50000: train_loss 0.6775, val loss 0.6764\n",
      "step 40300 of 50000: train_loss 0.6621, val loss 0.6744\n",
      "step 40400 of 50000: train_loss 0.6834, val loss 0.7014\n",
      "step 40500 of 50000: train_loss 0.6599, val loss 0.6902\n",
      "step 40600 of 50000: train_loss 0.6666, val loss 0.6766\n",
      "step 40700 of 50000: train_loss 0.6712, val loss 0.6780\n",
      "step 40800 of 50000: train_loss 0.6585, val loss 0.6780\n",
      "step 40900 of 50000: train_loss 0.6756, val loss 0.6770\n",
      "step 41000 of 50000: train_loss 0.6647, val loss 0.6598\n",
      "step 41100 of 50000: train_loss 0.6709, val loss 0.6899\n",
      "step 41200 of 50000: train_loss 0.6644, val loss 0.6620\n",
      "step 41300 of 50000: train_loss 0.6670, val loss 0.6755\n",
      "step 41400 of 50000: train_loss 0.6460, val loss 0.6753\n",
      "step 41500 of 50000: train_loss 0.6785, val loss 0.6638\n",
      "step 41600 of 50000: train_loss 0.6806, val loss 0.6879\n",
      "step 41700 of 50000: train_loss 0.6757, val loss 0.6998\n",
      "step 41800 of 50000: train_loss 0.6790, val loss 0.6878\n",
      "step 41900 of 50000: train_loss 0.6565, val loss 0.6701\n",
      "step 42000 of 50000: train_loss 0.6628, val loss 0.6696\n",
      "step 42100 of 50000: train_loss 0.6738, val loss 0.6800\n",
      "step 42200 of 50000: train_loss 0.6520, val loss 0.6713\n",
      "step 42300 of 50000: train_loss 0.6671, val loss 0.6867\n",
      "step 42400 of 50000: train_loss 0.6639, val loss 0.6897\n",
      "step 42500 of 50000: train_loss 0.6594, val loss 0.6745\n",
      "step 42600 of 50000: train_loss 0.6716, val loss 0.6763\n",
      "step 42700 of 50000: train_loss 0.6779, val loss 0.6788\n",
      "step 42800 of 50000: train_loss 0.6758, val loss 0.6935\n",
      "step 42900 of 50000: train_loss 0.6554, val loss 0.6788\n",
      "step 43000 of 50000: train_loss 0.6690, val loss 0.6649\n",
      "step 43100 of 50000: train_loss 0.6677, val loss 0.6741\n",
      "step 43200 of 50000: train_loss 0.6457, val loss 0.6881\n",
      "step 43300 of 50000: train_loss 0.6593, val loss 0.6802\n",
      "step 43400 of 50000: train_loss 0.6672, val loss 0.6616\n",
      "step 43500 of 50000: train_loss 0.6629, val loss 0.6692\n",
      "step 43600 of 50000: train_loss 0.6582, val loss 0.6974\n",
      "step 43700 of 50000: train_loss 0.6837, val loss 0.6552\n",
      "step 43800 of 50000: train_loss 0.6493, val loss 0.6872\n",
      "step 43900 of 50000: train_loss 0.6807, val loss 0.6918\n",
      "step 44000 of 50000: train_loss 0.6604, val loss 0.6711\n",
      "step 44100 of 50000: train_loss 0.6591, val loss 0.6638\n",
      "step 44200 of 50000: train_loss 0.6775, val loss 0.6654\n",
      "step 44300 of 50000: train_loss 0.6645, val loss 0.6800\n",
      "step 44400 of 50000: train_loss 0.6668, val loss 0.6853\n",
      "step 44500 of 50000: train_loss 0.6497, val loss 0.6800\n",
      "step 44600 of 50000: train_loss 0.6764, val loss 0.6898\n",
      "step 44700 of 50000: train_loss 0.6735, val loss 0.6747\n",
      "step 44800 of 50000: train_loss 0.6612, val loss 0.6687\n",
      "step 44900 of 50000: train_loss 0.6672, val loss 0.6704\n",
      "step 45000 of 50000: train_loss 0.6581, val loss 0.6759\n",
      "step 45100 of 50000: train_loss 0.6814, val loss 0.6787\n",
      "step 45200 of 50000: train_loss 0.6554, val loss 0.6960\n",
      "step 45300 of 50000: train_loss 0.6597, val loss 0.6764\n",
      "step 45400 of 50000: train_loss 0.6726, val loss 0.6823\n",
      "step 45500 of 50000: train_loss 0.6733, val loss 0.6938\n",
      "step 45600 of 50000: train_loss 0.6724, val loss 0.7092\n",
      "step 45700 of 50000: train_loss 0.6623, val loss 0.6722\n",
      "step 45800 of 50000: train_loss 0.6610, val loss 0.6738\n",
      "step 45900 of 50000: train_loss 0.6787, val loss 0.6767\n",
      "step 46000 of 50000: train_loss 0.6660, val loss 0.6642\n",
      "step 46100 of 50000: train_loss 0.6741, val loss 0.6782\n",
      "step 46200 of 50000: train_loss 0.6673, val loss 0.6948\n",
      "step 46300 of 50000: train_loss 0.6575, val loss 0.6760\n",
      "step 46400 of 50000: train_loss 0.6675, val loss 0.6705\n",
      "step 46500 of 50000: train_loss 0.6844, val loss 0.6677\n",
      "step 46600 of 50000: train_loss 0.6834, val loss 0.6756\n",
      "step 46700 of 50000: train_loss 0.6757, val loss 0.6769\n",
      "step 46800 of 50000: train_loss 0.6676, val loss 0.6824\n",
      "step 46900 of 50000: train_loss 0.6643, val loss 0.6807\n",
      "step 47000 of 50000: train_loss 0.6698, val loss 0.6788\n",
      "step 47100 of 50000: train_loss 0.6786, val loss 0.6851\n",
      "step 47200 of 50000: train_loss 0.6549, val loss 0.6566\n",
      "step 47300 of 50000: train_loss 0.6693, val loss 0.6711\n",
      "step 47400 of 50000: train_loss 0.6779, val loss 0.6831\n",
      "step 47500 of 50000: train_loss 0.6578, val loss 0.6678\n",
      "step 47600 of 50000: train_loss 0.6688, val loss 0.6901\n",
      "step 47700 of 50000: train_loss 0.6524, val loss 0.6813\n",
      "step 47800 of 50000: train_loss 0.6795, val loss 0.6844\n",
      "step 47900 of 50000: train_loss 0.6594, val loss 0.6657\n",
      "step 48000 of 50000: train_loss 0.6714, val loss 0.6851\n",
      "step 48100 of 50000: train_loss 0.6589, val loss 0.6711\n",
      "step 48200 of 50000: train_loss 0.6833, val loss 0.6734\n",
      "step 48300 of 50000: train_loss 0.6660, val loss 0.6682\n",
      "step 48400 of 50000: train_loss 0.6712, val loss 0.6732\n",
      "step 48500 of 50000: train_loss 0.6605, val loss 0.6747\n",
      "step 48600 of 50000: train_loss 0.6551, val loss 0.6754\n",
      "step 48700 of 50000: train_loss 0.6626, val loss 0.6797\n",
      "step 48800 of 50000: train_loss 0.6813, val loss 0.6666\n",
      "step 48900 of 50000: train_loss 0.6711, val loss 0.6747\n",
      "step 49000 of 50000: train_loss 0.6459, val loss 0.6673\n",
      "step 49100 of 50000: train_loss 0.6438, val loss 0.6670\n",
      "step 49200 of 50000: train_loss 0.6565, val loss 0.6766\n",
      "step 49300 of 50000: train_loss 0.6708, val loss 0.6739\n",
      "step 49400 of 50000: train_loss 0.6789, val loss 0.6846\n",
      "step 49500 of 50000: train_loss 0.6729, val loss 0.6773\n",
      "step 49600 of 50000: train_loss 0.6689, val loss 0.6613\n",
      "step 49700 of 50000: train_loss 0.6763, val loss 0.6678\n",
      "step 49800 of 50000: train_loss 0.6617, val loss 0.6889\n",
      "step 49900 of 50000: train_loss 0.6803, val loss 0.6660\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "545ff6c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T13:51:12.688006Z",
     "start_time": "2024-10-01T13:51:12.009894Z"
    }
   },
   "source": [
    "   \n",
    "model1.eval()\n",
    "inf = CausalInference(model=model1, device=device)\n",
    "\n",
    "int_nodes_vals0 = {'X1':np.array([0.0,])}\n",
    "int_nodes_vals1 = {'X1':np.array([1.0,])}\n",
    "effect_var = 'Y'\n",
    "effect_index = var_names1.index(effect_var)\n",
    "\n",
    "preds0 = inf.forward(all_data1, int_nodes_vals0)\n",
    "preds1 = inf.forward(all_data1, int_nodes_vals1)\n",
    "ATE_pred = (preds1[:,effect_index,:] - preds0[:,effect_index,:]).mean(0)\n",
    "eATE = np.abs(ATE_pred - ATE)\n",
    "print('ATE:', ATE, 'est ATE:', ATE_pred, 'error:', eATE)\n",
    "\n",
    "preds = model1(train_data.to(device))\n",
    "plt.scatter(train_data[:,effect_index,-1].detach().cpu().numpy(), preds[:, effect_index, -1].detach().cpu().numpy())\n",
    "print('Mean Squared Error Across All Vars:', ((train_data - preds.detach().cpu())**2).mean())\n",
    "print('Mean Squared Error Across Outcome:', ((train_data[:,effect_index,:] - preds[:,effect_index,:].detach().cpu())**2).mean())"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthewvowels/GitHub/Causal_Transformer/utils/inference.py:50: UserWarning: No mask has been specified. If padding has been used, the absence of a mask may lead to incorrect results.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE: [1.12] est ATE: [0.24324878] error: [0.87675122]\n",
      "Mean Squared Error Across All Vars: tensor(1.7037)\n",
      "Mean Squared Error Across Outcome: tensor(0.6656)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "442f6d34",
   "metadata": {},
   "source": [
    "## Incorrect DAG 2 (missing and reverse edges)"
   ]
  },
  {
   "cell_type": "code",
   "id": "e280e550",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-10-01T14:03:02.292131Z",
     "start_time": "2024-10-01T13:51:12.689044Z"
    }
   },
   "source": [
    "indices = np.arange(0, len(all_data2))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "val_inds = indices[:int(validation_fraction*len(indices))]\n",
    "train_inds = indices[int(validation_fraction*len(indices)):]\n",
    "train_data = all_data2[train_inds]\n",
    "val_data = all_data2[val_inds]\n",
    "train_data, val_data = torch.from_numpy(train_data).float(),  torch.from_numpy(val_data).float()\n",
    "\n",
    "input_dim = all_data2.shape[2]\n",
    "\n",
    "model2 = CaT(input_dim=input_dim,\n",
    "                    dropout_rate=dropout_rate,\n",
    "                    head_size=head_size,\n",
    "                    num_heads=num_heads,\n",
    "                    ff_n_embed=ff_n_embed,\n",
    "                    embed_dim= embed_dim,\n",
    "                    dag=DAGnx2,\n",
    "                    causal_ordering=causal_ordering2,\n",
    "                    n_layers=n_layers,\n",
    "                    device=device,\n",
    "                    var_types=var_types2, activation_function='Swish'\n",
    "                    ).to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model2.parameters(), lr=learning_rate)\n",
    "\n",
    "def get_batch(train_data, val_data, split, device, batch_size):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(0, len(data), (batch_size,))\n",
    "    x = data[ix]\n",
    "    return x.to(device)\n",
    "\n",
    "all_var_losses = {}\n",
    "for iter_ in range(0, max_iters):\n",
    "    # train and update the model\n",
    "    model2.train()\n",
    "\n",
    "    xb = get_batch(train_data=train_data, val_data=val_data, split='train', device=device, batch_size=batch_size)\n",
    "    xb_mod = torch.clone(xb.detach())\n",
    "    X, loss, loss_dict = model2(X=xb, targets=xb_mod)\n",
    "\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "    if iter_ % eval_interval == 0:  # evaluate the loss (no gradients)\n",
    "        for key in loss_dict.keys():\n",
    "            if key not in all_var_losses.keys():\n",
    "                all_var_losses[key] = []\n",
    "            all_var_losses[key].append(loss_dict[key])\n",
    "\n",
    "        model2.eval()\n",
    "        eval_loss = {}\n",
    "        for split in ['train', 'val']:\n",
    "            losses = torch.zeros(eval_iters)\n",
    "            for k in range(eval_iters):\n",
    "\n",
    "                xb = get_batch(train_data=train_data, val_data=val_data, split=split, device=device,\n",
    "                               batch_size=batch_size)\n",
    "                xb_mod = torch.clone(xb.detach())\n",
    "                X, loss, loss_dict = model2(X=xb, targets=xb_mod)\n",
    "                losses[k] = loss.item()\n",
    "            eval_loss[split] = losses.mean()\n",
    "        model2.train()\n",
    "        print(f\"step {iter_} of {max_iters}: train_loss {eval_loss['train']:.4f}, val loss {eval_loss['val']:.4f}\")\n",
    " "
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 of 50000: train_loss 2.7140, val loss 2.7551\n",
      "step 100 of 50000: train_loss 1.6856, val loss 1.6714\n",
      "step 200 of 50000: train_loss 1.7098, val loss 1.6826\n",
      "step 300 of 50000: train_loss 1.7293, val loss 1.6955\n",
      "step 400 of 50000: train_loss 1.7192, val loss 1.7076\n",
      "step 500 of 50000: train_loss 1.7010, val loss 1.6674\n",
      "step 600 of 50000: train_loss 1.6823, val loss 1.6626\n",
      "step 700 of 50000: train_loss 1.6808, val loss 1.7171\n",
      "step 800 of 50000: train_loss 1.6758, val loss 1.6900\n",
      "step 900 of 50000: train_loss 1.6901, val loss 1.6811\n",
      "step 1000 of 50000: train_loss 1.6877, val loss 1.6557\n",
      "step 1100 of 50000: train_loss 1.6500, val loss 1.6821\n",
      "step 1200 of 50000: train_loss 1.6711, val loss 1.6782\n",
      "step 1300 of 50000: train_loss 1.7011, val loss 1.6948\n",
      "step 1400 of 50000: train_loss 1.7033, val loss 1.6380\n",
      "step 1500 of 50000: train_loss 1.7064, val loss 1.7089\n",
      "step 1600 of 50000: train_loss 1.6918, val loss 1.6828\n",
      "step 1700 of 50000: train_loss 1.6787, val loss 1.6921\n",
      "step 1800 of 50000: train_loss 1.6926, val loss 1.6775\n",
      "step 1900 of 50000: train_loss 1.6548, val loss 1.6846\n",
      "step 2000 of 50000: train_loss 1.6870, val loss 1.6939\n",
      "step 2100 of 50000: train_loss 1.6617, val loss 1.6782\n",
      "step 2200 of 50000: train_loss 1.6725, val loss 1.6485\n",
      "step 2300 of 50000: train_loss 1.6829, val loss 1.7114\n",
      "step 2400 of 50000: train_loss 1.6527, val loss 1.6496\n",
      "step 2500 of 50000: train_loss 1.6549, val loss 1.6994\n",
      "step 2600 of 50000: train_loss 1.6912, val loss 1.7062\n",
      "step 2700 of 50000: train_loss 1.6592, val loss 1.6773\n",
      "step 2800 of 50000: train_loss 1.6940, val loss 1.6643\n",
      "step 2900 of 50000: train_loss 1.6887, val loss 1.6752\n",
      "step 3000 of 50000: train_loss 1.6965, val loss 1.6685\n",
      "step 3100 of 50000: train_loss 1.6828, val loss 1.7013\n",
      "step 3200 of 50000: train_loss 1.6558, val loss 1.6939\n",
      "step 3300 of 50000: train_loss 1.7117, val loss 1.6930\n",
      "step 3400 of 50000: train_loss 1.6957, val loss 1.6883\n",
      "step 3500 of 50000: train_loss 1.6848, val loss 1.6700\n",
      "step 3600 of 50000: train_loss 1.6867, val loss 1.6586\n",
      "step 3700 of 50000: train_loss 1.6812, val loss 1.6776\n",
      "step 3800 of 50000: train_loss 1.7017, val loss 1.6822\n",
      "step 3900 of 50000: train_loss 1.6700, val loss 1.7073\n",
      "step 4000 of 50000: train_loss 1.6685, val loss 1.6391\n",
      "step 4100 of 50000: train_loss 1.6743, val loss 1.6610\n",
      "step 4200 of 50000: train_loss 1.6663, val loss 1.6731\n",
      "step 4300 of 50000: train_loss 1.6827, val loss 1.6875\n",
      "step 4400 of 50000: train_loss 1.6898, val loss 1.6624\n",
      "step 4500 of 50000: train_loss 1.6849, val loss 1.6868\n",
      "step 4600 of 50000: train_loss 1.6502, val loss 1.6640\n",
      "step 4700 of 50000: train_loss 1.6697, val loss 1.6874\n",
      "step 4800 of 50000: train_loss 1.6804, val loss 1.6807\n",
      "step 4900 of 50000: train_loss 1.6778, val loss 1.6633\n",
      "step 5000 of 50000: train_loss 1.6752, val loss 1.6797\n",
      "step 5100 of 50000: train_loss 1.6832, val loss 1.6825\n",
      "step 5200 of 50000: train_loss 1.6561, val loss 1.6903\n",
      "step 5300 of 50000: train_loss 1.6655, val loss 1.6931\n",
      "step 5400 of 50000: train_loss 1.6676, val loss 1.6607\n",
      "step 5500 of 50000: train_loss 1.6955, val loss 1.6791\n",
      "step 5600 of 50000: train_loss 1.6817, val loss 1.6616\n",
      "step 5700 of 50000: train_loss 1.6824, val loss 1.6834\n",
      "step 5800 of 50000: train_loss 1.6728, val loss 1.6638\n",
      "step 5900 of 50000: train_loss 1.6820, val loss 1.6818\n",
      "step 6000 of 50000: train_loss 1.7139, val loss 1.6901\n",
      "step 6100 of 50000: train_loss 1.6727, val loss 1.6836\n",
      "step 6200 of 50000: train_loss 1.6531, val loss 1.6675\n",
      "step 6300 of 50000: train_loss 1.7021, val loss 1.6690\n",
      "step 6400 of 50000: train_loss 1.6710, val loss 1.7056\n",
      "step 6500 of 50000: train_loss 1.6963, val loss 1.6661\n",
      "step 6600 of 50000: train_loss 1.6760, val loss 1.6802\n",
      "step 6700 of 50000: train_loss 1.6624, val loss 1.6576\n",
      "step 6800 of 50000: train_loss 1.6482, val loss 1.6765\n",
      "step 6900 of 50000: train_loss 1.7029, val loss 1.6818\n",
      "step 7000 of 50000: train_loss 1.6731, val loss 1.6744\n",
      "step 7100 of 50000: train_loss 1.6787, val loss 1.6943\n",
      "step 7200 of 50000: train_loss 1.6727, val loss 1.6759\n",
      "step 7300 of 50000: train_loss 1.6778, val loss 1.6913\n",
      "step 7400 of 50000: train_loss 1.6750, val loss 1.6779\n",
      "step 7500 of 50000: train_loss 1.6792, val loss 1.6868\n",
      "step 7600 of 50000: train_loss 1.6930, val loss 1.6578\n",
      "step 7700 of 50000: train_loss 1.6633, val loss 1.6992\n",
      "step 7800 of 50000: train_loss 1.6599, val loss 1.6458\n",
      "step 7900 of 50000: train_loss 1.6706, val loss 1.6939\n",
      "step 8000 of 50000: train_loss 1.6695, val loss 1.6909\n",
      "step 8100 of 50000: train_loss 1.6625, val loss 1.6675\n",
      "step 8200 of 50000: train_loss 1.6717, val loss 1.6905\n",
      "step 8300 of 50000: train_loss 1.6507, val loss 1.6676\n",
      "step 8400 of 50000: train_loss 1.7128, val loss 1.6354\n",
      "step 8500 of 50000: train_loss 1.6672, val loss 1.6758\n",
      "step 8600 of 50000: train_loss 1.7059, val loss 1.6679\n",
      "step 8700 of 50000: train_loss 1.6931, val loss 1.6842\n",
      "step 8800 of 50000: train_loss 1.6626, val loss 1.6754\n",
      "step 8900 of 50000: train_loss 1.6531, val loss 1.6738\n",
      "step 9000 of 50000: train_loss 1.6813, val loss 1.6682\n",
      "step 9100 of 50000: train_loss 1.6374, val loss 1.6555\n",
      "step 9200 of 50000: train_loss 1.6747, val loss 1.6845\n",
      "step 9300 of 50000: train_loss 1.7092, val loss 1.7032\n",
      "step 9400 of 50000: train_loss 1.6977, val loss 1.6927\n",
      "step 9500 of 50000: train_loss 1.6487, val loss 1.6914\n",
      "step 9600 of 50000: train_loss 1.6707, val loss 1.6538\n",
      "step 9700 of 50000: train_loss 1.6497, val loss 1.6822\n",
      "step 9800 of 50000: train_loss 1.6665, val loss 1.7059\n",
      "step 9900 of 50000: train_loss 1.6849, val loss 1.6455\n",
      "step 10000 of 50000: train_loss 1.6810, val loss 1.6921\n",
      "step 10100 of 50000: train_loss 1.6678, val loss 1.6668\n",
      "step 10200 of 50000: train_loss 1.6905, val loss 1.6732\n",
      "step 10300 of 50000: train_loss 1.6535, val loss 1.6637\n",
      "step 10400 of 50000: train_loss 1.6600, val loss 1.6694\n",
      "step 10500 of 50000: train_loss 1.6627, val loss 1.6197\n",
      "step 10600 of 50000: train_loss 1.6505, val loss 1.6791\n",
      "step 10700 of 50000: train_loss 1.6963, val loss 1.6761\n",
      "step 10800 of 50000: train_loss 1.6426, val loss 1.6923\n",
      "step 10900 of 50000: train_loss 1.6486, val loss 1.6530\n",
      "step 11000 of 50000: train_loss 1.6666, val loss 1.6481\n",
      "step 11100 of 50000: train_loss 1.6687, val loss 1.6558\n",
      "step 11200 of 50000: train_loss 1.6602, val loss 1.6968\n",
      "step 11300 of 50000: train_loss 1.6544, val loss 1.6949\n",
      "step 11400 of 50000: train_loss 1.6636, val loss 1.6899\n",
      "step 11500 of 50000: train_loss 1.6647, val loss 1.6701\n",
      "step 11600 of 50000: train_loss 1.6632, val loss 1.7162\n",
      "step 11700 of 50000: train_loss 1.7092, val loss 1.6968\n",
      "step 11800 of 50000: train_loss 1.6644, val loss 1.6991\n",
      "step 11900 of 50000: train_loss 1.6720, val loss 1.6630\n",
      "step 12000 of 50000: train_loss 1.6578, val loss 1.6544\n",
      "step 12100 of 50000: train_loss 1.6541, val loss 1.6622\n",
      "step 12200 of 50000: train_loss 1.6430, val loss 1.6775\n",
      "step 12300 of 50000: train_loss 1.6519, val loss 1.6540\n",
      "step 12400 of 50000: train_loss 1.6623, val loss 1.6625\n",
      "step 12500 of 50000: train_loss 1.6967, val loss 1.6919\n",
      "step 12600 of 50000: train_loss 1.6645, val loss 1.6961\n",
      "step 12700 of 50000: train_loss 1.6775, val loss 1.6604\n",
      "step 12800 of 50000: train_loss 1.7056, val loss 1.6336\n",
      "step 12900 of 50000: train_loss 1.6791, val loss 1.6635\n",
      "step 13000 of 50000: train_loss 1.6963, val loss 1.6991\n",
      "step 13100 of 50000: train_loss 1.6744, val loss 1.6353\n",
      "step 13200 of 50000: train_loss 1.6769, val loss 1.7008\n",
      "step 13300 of 50000: train_loss 1.6437, val loss 1.6848\n",
      "step 13400 of 50000: train_loss 1.6490, val loss 1.6698\n",
      "step 13500 of 50000: train_loss 1.6734, val loss 1.6587\n",
      "step 13600 of 50000: train_loss 1.6361, val loss 1.6782\n",
      "step 13700 of 50000: train_loss 1.6762, val loss 1.6680\n",
      "step 13800 of 50000: train_loss 1.6739, val loss 1.6514\n",
      "step 13900 of 50000: train_loss 1.6683, val loss 1.6734\n",
      "step 14000 of 50000: train_loss 1.6532, val loss 1.6704\n",
      "step 14100 of 50000: train_loss 1.6594, val loss 1.6553\n",
      "step 14200 of 50000: train_loss 1.6991, val loss 1.6681\n",
      "step 14300 of 50000: train_loss 1.6459, val loss 1.6723\n",
      "step 14400 of 50000: train_loss 1.6794, val loss 1.6678\n",
      "step 14500 of 50000: train_loss 1.7234, val loss 1.6412\n",
      "step 14600 of 50000: train_loss 1.6898, val loss 1.6986\n",
      "step 14700 of 50000: train_loss 1.6942, val loss 1.6728\n",
      "step 14800 of 50000: train_loss 1.6522, val loss 1.6453\n",
      "step 14900 of 50000: train_loss 1.6835, val loss 1.6663\n",
      "step 15000 of 50000: train_loss 1.6752, val loss 1.6594\n",
      "step 15100 of 50000: train_loss 1.6589, val loss 1.6680\n",
      "step 15200 of 50000: train_loss 1.6899, val loss 1.6668\n",
      "step 15300 of 50000: train_loss 1.6655, val loss 1.6862\n",
      "step 15400 of 50000: train_loss 1.6809, val loss 1.6645\n",
      "step 15500 of 50000: train_loss 1.6793, val loss 1.6595\n",
      "step 15600 of 50000: train_loss 1.6799, val loss 1.6331\n",
      "step 15700 of 50000: train_loss 1.7054, val loss 1.6632\n",
      "step 15800 of 50000: train_loss 1.6977, val loss 1.6648\n",
      "step 15900 of 50000: train_loss 1.6895, val loss 1.6993\n",
      "step 16000 of 50000: train_loss 1.6681, val loss 1.6962\n",
      "step 16100 of 50000: train_loss 1.6915, val loss 1.6668\n",
      "step 16200 of 50000: train_loss 1.6583, val loss 1.6695\n",
      "step 16300 of 50000: train_loss 1.7119, val loss 1.7109\n",
      "step 16400 of 50000: train_loss 1.6956, val loss 1.6705\n",
      "step 16500 of 50000: train_loss 1.6691, val loss 1.7011\n",
      "step 16600 of 50000: train_loss 1.6835, val loss 1.6326\n",
      "step 16700 of 50000: train_loss 1.6912, val loss 1.6391\n",
      "step 16800 of 50000: train_loss 1.6975, val loss 1.6592\n",
      "step 16900 of 50000: train_loss 1.6636, val loss 1.6766\n",
      "step 17000 of 50000: train_loss 1.6833, val loss 1.6511\n",
      "step 17100 of 50000: train_loss 1.6515, val loss 1.6791\n",
      "step 17200 of 50000: train_loss 1.6993, val loss 1.6636\n",
      "step 17300 of 50000: train_loss 1.6701, val loss 1.6793\n",
      "step 17400 of 50000: train_loss 1.7026, val loss 1.6574\n",
      "step 17500 of 50000: train_loss 1.6875, val loss 1.6789\n",
      "step 17600 of 50000: train_loss 1.6801, val loss 1.6862\n",
      "step 17700 of 50000: train_loss 1.6651, val loss 1.6707\n",
      "step 17800 of 50000: train_loss 1.6943, val loss 1.6806\n",
      "step 17900 of 50000: train_loss 1.7013, val loss 1.6960\n",
      "step 18000 of 50000: train_loss 1.6811, val loss 1.6444\n",
      "step 18100 of 50000: train_loss 1.6835, val loss 1.6690\n",
      "step 18200 of 50000: train_loss 1.6357, val loss 1.6740\n",
      "step 18300 of 50000: train_loss 1.6484, val loss 1.6584\n",
      "step 18400 of 50000: train_loss 1.6617, val loss 1.6560\n",
      "step 18500 of 50000: train_loss 1.6531, val loss 1.6518\n",
      "step 18600 of 50000: train_loss 1.6667, val loss 1.6504\n",
      "step 18700 of 50000: train_loss 1.6905, val loss 1.6735\n",
      "step 18800 of 50000: train_loss 1.6568, val loss 1.6728\n",
      "step 18900 of 50000: train_loss 1.6585, val loss 1.6885\n",
      "step 19000 of 50000: train_loss 1.6773, val loss 1.6542\n",
      "step 19100 of 50000: train_loss 1.6587, val loss 1.6628\n",
      "step 19200 of 50000: train_loss 1.7034, val loss 1.7021\n",
      "step 19300 of 50000: train_loss 1.6845, val loss 1.6629\n",
      "step 19400 of 50000: train_loss 1.6694, val loss 1.7324\n",
      "step 19500 of 50000: train_loss 1.6961, val loss 1.7084\n",
      "step 19600 of 50000: train_loss 1.6913, val loss 1.6794\n",
      "step 19700 of 50000: train_loss 1.6559, val loss 1.6611\n",
      "step 19800 of 50000: train_loss 1.6862, val loss 1.6816\n",
      "step 19900 of 50000: train_loss 1.6582, val loss 1.6741\n",
      "step 20000 of 50000: train_loss 1.6977, val loss 1.6615\n",
      "step 20100 of 50000: train_loss 1.6626, val loss 1.6760\n",
      "step 20200 of 50000: train_loss 1.6889, val loss 1.6923\n",
      "step 20300 of 50000: train_loss 1.6671, val loss 1.6758\n",
      "step 20400 of 50000: train_loss 1.6742, val loss 1.6748\n",
      "step 20500 of 50000: train_loss 1.6444, val loss 1.6783\n",
      "step 20600 of 50000: train_loss 1.6456, val loss 1.6538\n",
      "step 20700 of 50000: train_loss 1.6653, val loss 1.6792\n",
      "step 20800 of 50000: train_loss 1.6630, val loss 1.6660\n",
      "step 20900 of 50000: train_loss 1.6715, val loss 1.6294\n",
      "step 21000 of 50000: train_loss 1.6953, val loss 1.6813\n",
      "step 21100 of 50000: train_loss 1.6693, val loss 1.6800\n",
      "step 21200 of 50000: train_loss 1.6563, val loss 1.6543\n",
      "step 21300 of 50000: train_loss 1.6547, val loss 1.6768\n",
      "step 21400 of 50000: train_loss 1.6627, val loss 1.6565\n",
      "step 21500 of 50000: train_loss 1.6652, val loss 1.6383\n",
      "step 21600 of 50000: train_loss 1.6786, val loss 1.6358\n",
      "step 21700 of 50000: train_loss 1.6369, val loss 1.6579\n",
      "step 21800 of 50000: train_loss 1.6753, val loss 1.7056\n",
      "step 21900 of 50000: train_loss 1.7149, val loss 1.7168\n",
      "step 22000 of 50000: train_loss 1.6944, val loss 1.6700\n",
      "step 22100 of 50000: train_loss 1.6546, val loss 1.6736\n",
      "step 22200 of 50000: train_loss 1.6764, val loss 1.6715\n",
      "step 22300 of 50000: train_loss 1.6724, val loss 1.6686\n",
      "step 22400 of 50000: train_loss 1.6650, val loss 1.7132\n",
      "step 22500 of 50000: train_loss 1.6560, val loss 1.6748\n",
      "step 22600 of 50000: train_loss 1.6711, val loss 1.6563\n",
      "step 22700 of 50000: train_loss 1.6785, val loss 1.6706\n",
      "step 22800 of 50000: train_loss 1.6909, val loss 1.6762\n",
      "step 22900 of 50000: train_loss 1.6965, val loss 1.7037\n",
      "step 23000 of 50000: train_loss 1.6897, val loss 1.6959\n",
      "step 23100 of 50000: train_loss 1.7051, val loss 1.7077\n",
      "step 23200 of 50000: train_loss 1.6555, val loss 1.6514\n",
      "step 23300 of 50000: train_loss 1.7009, val loss 1.6763\n",
      "step 23400 of 50000: train_loss 1.6872, val loss 1.6793\n",
      "step 23500 of 50000: train_loss 1.6625, val loss 1.6738\n",
      "step 23600 of 50000: train_loss 1.6818, val loss 1.6734\n",
      "step 23700 of 50000: train_loss 1.6736, val loss 1.6777\n",
      "step 23800 of 50000: train_loss 1.6817, val loss 1.6450\n",
      "step 23900 of 50000: train_loss 1.6920, val loss 1.6514\n",
      "step 24000 of 50000: train_loss 1.6930, val loss 1.6881\n",
      "step 24100 of 50000: train_loss 1.6753, val loss 1.6590\n",
      "step 24200 of 50000: train_loss 1.6568, val loss 1.6970\n",
      "step 24300 of 50000: train_loss 1.6580, val loss 1.6528\n",
      "step 24400 of 50000: train_loss 1.6453, val loss 1.6611\n",
      "step 24500 of 50000: train_loss 1.6700, val loss 1.7056\n",
      "step 24600 of 50000: train_loss 1.6883, val loss 1.6526\n",
      "step 24700 of 50000: train_loss 1.6740, val loss 1.6887\n",
      "step 24800 of 50000: train_loss 1.6397, val loss 1.6296\n",
      "step 24900 of 50000: train_loss 1.6966, val loss 1.6529\n",
      "step 25000 of 50000: train_loss 1.6871, val loss 1.6556\n",
      "step 25100 of 50000: train_loss 1.6856, val loss 1.7104\n",
      "step 25200 of 50000: train_loss 1.6932, val loss 1.6449\n",
      "step 25300 of 50000: train_loss 1.6967, val loss 1.6892\n",
      "step 25400 of 50000: train_loss 1.6710, val loss 1.6810\n",
      "step 25500 of 50000: train_loss 1.6771, val loss 1.6390\n",
      "step 25600 of 50000: train_loss 1.6993, val loss 1.6610\n",
      "step 25700 of 50000: train_loss 1.6799, val loss 1.6922\n",
      "step 25800 of 50000: train_loss 1.6361, val loss 1.6886\n",
      "step 25900 of 50000: train_loss 1.6675, val loss 1.6613\n",
      "step 26000 of 50000: train_loss 1.6592, val loss 1.6786\n",
      "step 26100 of 50000: train_loss 1.6694, val loss 1.6737\n",
      "step 26200 of 50000: train_loss 1.6897, val loss 1.6511\n",
      "step 26300 of 50000: train_loss 1.6492, val loss 1.6448\n",
      "step 26400 of 50000: train_loss 1.6589, val loss 1.6677\n",
      "step 26500 of 50000: train_loss 1.6553, val loss 1.6775\n",
      "step 26600 of 50000: train_loss 1.6424, val loss 1.6754\n",
      "step 26700 of 50000: train_loss 1.6440, val loss 1.6291\n",
      "step 26800 of 50000: train_loss 1.6755, val loss 1.6594\n",
      "step 26900 of 50000: train_loss 1.6573, val loss 1.7054\n",
      "step 27000 of 50000: train_loss 1.6813, val loss 1.6617\n",
      "step 27100 of 50000: train_loss 1.6920, val loss 1.6883\n",
      "step 27200 of 50000: train_loss 1.6679, val loss 1.6394\n",
      "step 27300 of 50000: train_loss 1.6599, val loss 1.6719\n",
      "step 27400 of 50000: train_loss 1.6639, val loss 1.6872\n",
      "step 27500 of 50000: train_loss 1.6592, val loss 1.6851\n",
      "step 27600 of 50000: train_loss 1.6794, val loss 1.6452\n",
      "step 27700 of 50000: train_loss 1.6917, val loss 1.6569\n",
      "step 27800 of 50000: train_loss 1.6464, val loss 1.6551\n",
      "step 27900 of 50000: train_loss 1.6665, val loss 1.6585\n",
      "step 28000 of 50000: train_loss 1.6928, val loss 1.6935\n",
      "step 28100 of 50000: train_loss 1.6293, val loss 1.6746\n",
      "step 28200 of 50000: train_loss 1.6620, val loss 1.6632\n",
      "step 28300 of 50000: train_loss 1.6787, val loss 1.6655\n",
      "step 28400 of 50000: train_loss 1.6801, val loss 1.6711\n",
      "step 28500 of 50000: train_loss 1.6579, val loss 1.6791\n",
      "step 28600 of 50000: train_loss 1.6963, val loss 1.6656\n",
      "step 28700 of 50000: train_loss 1.7021, val loss 1.6638\n",
      "step 28800 of 50000: train_loss 1.6673, val loss 1.6749\n",
      "step 28900 of 50000: train_loss 1.6782, val loss 1.6895\n",
      "step 29000 of 50000: train_loss 1.6705, val loss 1.6658\n",
      "step 29100 of 50000: train_loss 1.6668, val loss 1.6770\n",
      "step 29200 of 50000: train_loss 1.6414, val loss 1.6619\n",
      "step 29300 of 50000: train_loss 1.6466, val loss 1.6531\n",
      "step 29400 of 50000: train_loss 1.7018, val loss 1.6778\n",
      "step 29500 of 50000: train_loss 1.6800, val loss 1.6846\n",
      "step 29600 of 50000: train_loss 1.6738, val loss 1.6506\n",
      "step 29700 of 50000: train_loss 1.6700, val loss 1.6859\n",
      "step 29800 of 50000: train_loss 1.6848, val loss 1.6623\n",
      "step 29900 of 50000: train_loss 1.6736, val loss 1.6840\n",
      "step 30000 of 50000: train_loss 1.7094, val loss 1.6768\n",
      "step 30100 of 50000: train_loss 1.6521, val loss 1.6328\n",
      "step 30200 of 50000: train_loss 1.6955, val loss 1.6935\n",
      "step 30300 of 50000: train_loss 1.6638, val loss 1.6517\n",
      "step 30400 of 50000: train_loss 1.6786, val loss 1.6504\n",
      "step 30500 of 50000: train_loss 1.6542, val loss 1.6739\n",
      "step 30600 of 50000: train_loss 1.6691, val loss 1.6551\n",
      "step 30700 of 50000: train_loss 1.6815, val loss 1.6522\n",
      "step 30800 of 50000: train_loss 1.6867, val loss 1.6811\n",
      "step 30900 of 50000: train_loss 1.6666, val loss 1.6648\n",
      "step 31000 of 50000: train_loss 1.7034, val loss 1.6669\n",
      "step 31100 of 50000: train_loss 1.6856, val loss 1.6621\n",
      "step 31200 of 50000: train_loss 1.6744, val loss 1.6682\n",
      "step 31300 of 50000: train_loss 1.7085, val loss 1.6918\n",
      "step 31400 of 50000: train_loss 1.6501, val loss 1.6593\n",
      "step 31500 of 50000: train_loss 1.6536, val loss 1.6822\n",
      "step 31600 of 50000: train_loss 1.6793, val loss 1.6965\n",
      "step 31700 of 50000: train_loss 1.6937, val loss 1.6403\n",
      "step 31800 of 50000: train_loss 1.6794, val loss 1.6704\n",
      "step 31900 of 50000: train_loss 1.6531, val loss 1.6630\n",
      "step 32000 of 50000: train_loss 1.6882, val loss 1.6802\n",
      "step 32100 of 50000: train_loss 1.6488, val loss 1.6826\n",
      "step 32200 of 50000: train_loss 1.6283, val loss 1.6965\n",
      "step 32300 of 50000: train_loss 1.6469, val loss 1.6786\n",
      "step 32400 of 50000: train_loss 1.6891, val loss 1.6744\n",
      "step 32500 of 50000: train_loss 1.6769, val loss 1.7011\n",
      "step 32600 of 50000: train_loss 1.6723, val loss 1.7046\n",
      "step 32700 of 50000: train_loss 1.6799, val loss 1.6723\n",
      "step 32800 of 50000: train_loss 1.6788, val loss 1.6604\n",
      "step 32900 of 50000: train_loss 1.6780, val loss 1.6574\n",
      "step 33000 of 50000: train_loss 1.6989, val loss 1.6657\n",
      "step 33100 of 50000: train_loss 1.6554, val loss 1.6501\n",
      "step 33200 of 50000: train_loss 1.6568, val loss 1.6717\n",
      "step 33300 of 50000: train_loss 1.6703, val loss 1.6417\n",
      "step 33400 of 50000: train_loss 1.6683, val loss 1.7054\n",
      "step 33500 of 50000: train_loss 1.6643, val loss 1.6531\n",
      "step 33600 of 50000: train_loss 1.6665, val loss 1.6827\n",
      "step 33700 of 50000: train_loss 1.6690, val loss 1.6555\n",
      "step 33800 of 50000: train_loss 1.6860, val loss 1.6598\n",
      "step 33900 of 50000: train_loss 1.7063, val loss 1.6819\n",
      "step 34000 of 50000: train_loss 1.6539, val loss 1.6549\n",
      "step 34100 of 50000: train_loss 1.6523, val loss 1.6567\n",
      "step 34200 of 50000: train_loss 1.7043, val loss 1.6929\n",
      "step 34300 of 50000: train_loss 1.6700, val loss 1.6882\n",
      "step 34400 of 50000: train_loss 1.6463, val loss 1.6823\n",
      "step 34500 of 50000: train_loss 1.6569, val loss 1.6810\n",
      "step 34600 of 50000: train_loss 1.6786, val loss 1.6677\n",
      "step 34700 of 50000: train_loss 1.6776, val loss 1.6909\n",
      "step 34800 of 50000: train_loss 1.6916, val loss 1.6707\n",
      "step 34900 of 50000: train_loss 1.6660, val loss 1.6489\n",
      "step 35000 of 50000: train_loss 1.6632, val loss 1.6487\n",
      "step 35100 of 50000: train_loss 1.6687, val loss 1.6359\n",
      "step 35200 of 50000: train_loss 1.6738, val loss 1.6365\n",
      "step 35300 of 50000: train_loss 1.6687, val loss 1.6790\n",
      "step 35400 of 50000: train_loss 1.6855, val loss 1.6527\n",
      "step 35500 of 50000: train_loss 1.6748, val loss 1.6492\n",
      "step 35600 of 50000: train_loss 1.6989, val loss 1.6634\n",
      "step 35700 of 50000: train_loss 1.6764, val loss 1.6881\n",
      "step 35800 of 50000: train_loss 1.6727, val loss 1.6833\n",
      "step 35900 of 50000: train_loss 1.6410, val loss 1.6665\n",
      "step 36000 of 50000: train_loss 1.6670, val loss 1.6832\n",
      "step 36100 of 50000: train_loss 1.6874, val loss 1.6816\n",
      "step 36200 of 50000: train_loss 1.6687, val loss 1.6692\n",
      "step 36300 of 50000: train_loss 1.6702, val loss 1.6897\n",
      "step 36400 of 50000: train_loss 1.6680, val loss 1.6614\n",
      "step 36500 of 50000: train_loss 1.6940, val loss 1.6527\n",
      "step 36600 of 50000: train_loss 1.6549, val loss 1.6440\n",
      "step 36700 of 50000: train_loss 1.6758, val loss 1.6632\n",
      "step 36800 of 50000: train_loss 1.6873, val loss 1.6719\n",
      "step 36900 of 50000: train_loss 1.6705, val loss 1.6331\n",
      "step 37000 of 50000: train_loss 1.6674, val loss 1.6626\n",
      "step 37100 of 50000: train_loss 1.6458, val loss 1.6901\n",
      "step 37200 of 50000: train_loss 1.6498, val loss 1.7015\n",
      "step 37300 of 50000: train_loss 1.6576, val loss 1.6525\n",
      "step 37400 of 50000: train_loss 1.6459, val loss 1.6786\n",
      "step 37500 of 50000: train_loss 1.6783, val loss 1.6510\n",
      "step 37600 of 50000: train_loss 1.6621, val loss 1.6266\n",
      "step 37700 of 50000: train_loss 1.6932, val loss 1.6649\n",
      "step 37800 of 50000: train_loss 1.6882, val loss 1.6629\n",
      "step 37900 of 50000: train_loss 1.6965, val loss 1.6594\n",
      "step 38000 of 50000: train_loss 1.6568, val loss 1.6800\n",
      "step 38100 of 50000: train_loss 1.6343, val loss 1.6806\n",
      "step 38200 of 50000: train_loss 1.6805, val loss 1.6804\n",
      "step 38300 of 50000: train_loss 1.6531, val loss 1.6731\n",
      "step 38400 of 50000: train_loss 1.6762, val loss 1.6334\n",
      "step 38500 of 50000: train_loss 1.6614, val loss 1.6946\n",
      "step 38600 of 50000: train_loss 1.6327, val loss 1.6745\n",
      "step 38700 of 50000: train_loss 1.6444, val loss 1.6587\n",
      "step 38800 of 50000: train_loss 1.6850, val loss 1.6889\n",
      "step 38900 of 50000: train_loss 1.6760, val loss 1.6557\n",
      "step 39000 of 50000: train_loss 1.6774, val loss 1.6513\n",
      "step 39100 of 50000: train_loss 1.6686, val loss 1.6694\n",
      "step 39200 of 50000: train_loss 1.6951, val loss 1.6513\n",
      "step 39300 of 50000: train_loss 1.6447, val loss 1.6687\n",
      "step 39400 of 50000: train_loss 1.6538, val loss 1.6506\n",
      "step 39500 of 50000: train_loss 1.6866, val loss 1.6857\n",
      "step 39600 of 50000: train_loss 1.6735, val loss 1.6645\n",
      "step 39700 of 50000: train_loss 1.6785, val loss 1.6876\n",
      "step 39800 of 50000: train_loss 1.6552, val loss 1.7046\n",
      "step 39900 of 50000: train_loss 1.6798, val loss 1.6784\n",
      "step 40000 of 50000: train_loss 1.6896, val loss 1.6720\n",
      "step 40100 of 50000: train_loss 1.6625, val loss 1.6887\n",
      "step 40200 of 50000: train_loss 1.6673, val loss 1.6687\n",
      "step 40300 of 50000: train_loss 1.7031, val loss 1.7142\n",
      "step 40400 of 50000: train_loss 1.6882, val loss 1.7002\n",
      "step 40500 of 50000: train_loss 1.6105, val loss 1.6679\n",
      "step 40600 of 50000: train_loss 1.6558, val loss 1.6723\n",
      "step 40700 of 50000: train_loss 1.6882, val loss 1.6311\n",
      "step 40800 of 50000: train_loss 1.6909, val loss 1.6452\n",
      "step 40900 of 50000: train_loss 1.6633, val loss 1.6648\n",
      "step 41000 of 50000: train_loss 1.6677, val loss 1.6683\n",
      "step 41100 of 50000: train_loss 1.6627, val loss 1.6936\n",
      "step 41200 of 50000: train_loss 1.6820, val loss 1.6626\n",
      "step 41300 of 50000: train_loss 1.6571, val loss 1.6846\n",
      "step 41400 of 50000: train_loss 1.6715, val loss 1.6546\n",
      "step 41500 of 50000: train_loss 1.6840, val loss 1.6684\n",
      "step 41600 of 50000: train_loss 1.6812, val loss 1.6513\n",
      "step 41700 of 50000: train_loss 1.6474, val loss 1.6820\n",
      "step 41800 of 50000: train_loss 1.6688, val loss 1.6757\n",
      "step 41900 of 50000: train_loss 1.7122, val loss 1.6550\n",
      "step 42000 of 50000: train_loss 1.6690, val loss 1.6677\n",
      "step 42100 of 50000: train_loss 1.6365, val loss 1.6819\n",
      "step 42200 of 50000: train_loss 1.7142, val loss 1.6620\n",
      "step 42300 of 50000: train_loss 1.6777, val loss 1.6787\n",
      "step 42400 of 50000: train_loss 1.6785, val loss 1.6610\n",
      "step 42500 of 50000: train_loss 1.6725, val loss 1.6716\n",
      "step 42600 of 50000: train_loss 1.6495, val loss 1.6519\n",
      "step 42700 of 50000: train_loss 1.6638, val loss 1.6542\n",
      "step 42800 of 50000: train_loss 1.6795, val loss 1.6573\n",
      "step 42900 of 50000: train_loss 1.6720, val loss 1.6754\n",
      "step 43000 of 50000: train_loss 1.6813, val loss 1.6637\n",
      "step 43100 of 50000: train_loss 1.6745, val loss 1.6701\n",
      "step 43200 of 50000: train_loss 1.6568, val loss 1.6495\n",
      "step 43300 of 50000: train_loss 1.6731, val loss 1.6900\n",
      "step 43400 of 50000: train_loss 1.6854, val loss 1.7075\n",
      "step 43500 of 50000: train_loss 1.6605, val loss 1.6666\n",
      "step 43600 of 50000: train_loss 1.6566, val loss 1.6362\n",
      "step 43700 of 50000: train_loss 1.6504, val loss 1.6750\n",
      "step 43800 of 50000: train_loss 1.6778, val loss 1.6890\n",
      "step 43900 of 50000: train_loss 1.6766, val loss 1.6509\n",
      "step 44000 of 50000: train_loss 1.6499, val loss 1.6897\n",
      "step 44100 of 50000: train_loss 1.6740, val loss 1.7134\n",
      "step 44200 of 50000: train_loss 1.6765, val loss 1.6714\n",
      "step 44300 of 50000: train_loss 1.6454, val loss 1.6705\n",
      "step 44400 of 50000: train_loss 1.7079, val loss 1.6961\n",
      "step 44500 of 50000: train_loss 1.6557, val loss 1.6474\n",
      "step 44600 of 50000: train_loss 1.6550, val loss 1.6657\n",
      "step 44700 of 50000: train_loss 1.6770, val loss 1.6270\n",
      "step 44800 of 50000: train_loss 1.6864, val loss 1.6605\n",
      "step 44900 of 50000: train_loss 1.6915, val loss 1.6642\n",
      "step 45000 of 50000: train_loss 1.6933, val loss 1.6874\n",
      "step 45100 of 50000: train_loss 1.6748, val loss 1.6823\n",
      "step 45200 of 50000: train_loss 1.6800, val loss 1.6789\n",
      "step 45300 of 50000: train_loss 1.6562, val loss 1.6634\n",
      "step 45400 of 50000: train_loss 1.7027, val loss 1.6796\n",
      "step 45500 of 50000: train_loss 1.6554, val loss 1.6595\n",
      "step 45600 of 50000: train_loss 1.6972, val loss 1.6776\n",
      "step 45700 of 50000: train_loss 1.6532, val loss 1.6759\n",
      "step 45800 of 50000: train_loss 1.6724, val loss 1.6825\n",
      "step 45900 of 50000: train_loss 1.6889, val loss 1.6395\n",
      "step 46000 of 50000: train_loss 1.6717, val loss 1.6734\n",
      "step 46100 of 50000: train_loss 1.6798, val loss 1.6530\n",
      "step 46200 of 50000: train_loss 1.6618, val loss 1.6598\n",
      "step 46300 of 50000: train_loss 1.6743, val loss 1.6620\n",
      "step 46400 of 50000: train_loss 1.6864, val loss 1.6629\n",
      "step 46500 of 50000: train_loss 1.6867, val loss 1.6565\n",
      "step 46600 of 50000: train_loss 1.6823, val loss 1.6659\n",
      "step 46700 of 50000: train_loss 1.7010, val loss 1.6857\n",
      "step 46800 of 50000: train_loss 1.6777, val loss 1.6508\n",
      "step 46900 of 50000: train_loss 1.6670, val loss 1.6739\n",
      "step 47000 of 50000: train_loss 1.6588, val loss 1.6524\n",
      "step 47100 of 50000: train_loss 1.6746, val loss 1.6749\n",
      "step 47200 of 50000: train_loss 1.6965, val loss 1.6905\n",
      "step 47300 of 50000: train_loss 1.6721, val loss 1.6784\n",
      "step 47400 of 50000: train_loss 1.6573, val loss 1.6649\n",
      "step 47500 of 50000: train_loss 1.6659, val loss 1.6356\n",
      "step 47600 of 50000: train_loss 1.6680, val loss 1.6399\n",
      "step 47700 of 50000: train_loss 1.6784, val loss 1.6563\n",
      "step 47800 of 50000: train_loss 1.6795, val loss 1.6944\n",
      "step 47900 of 50000: train_loss 1.6737, val loss 1.6628\n",
      "step 48000 of 50000: train_loss 1.6840, val loss 1.6828\n",
      "step 48100 of 50000: train_loss 1.6679, val loss 1.6842\n",
      "step 48200 of 50000: train_loss 1.6977, val loss 1.6817\n",
      "step 48300 of 50000: train_loss 1.6451, val loss 1.6686\n",
      "step 48400 of 50000: train_loss 1.6602, val loss 1.7011\n",
      "step 48500 of 50000: train_loss 1.6549, val loss 1.6384\n",
      "step 48600 of 50000: train_loss 1.6698, val loss 1.6726\n",
      "step 48700 of 50000: train_loss 1.6592, val loss 1.6755\n",
      "step 48800 of 50000: train_loss 1.6789, val loss 1.6773\n",
      "step 48900 of 50000: train_loss 1.6615, val loss 1.6626\n",
      "step 49000 of 50000: train_loss 1.6471, val loss 1.7193\n",
      "step 49100 of 50000: train_loss 1.6952, val loss 1.6620\n",
      "step 49200 of 50000: train_loss 1.6812, val loss 1.6566\n",
      "step 49300 of 50000: train_loss 1.6511, val loss 1.6669\n",
      "step 49400 of 50000: train_loss 1.6579, val loss 1.6691\n",
      "step 49500 of 50000: train_loss 1.6692, val loss 1.6464\n",
      "step 49600 of 50000: train_loss 1.6568, val loss 1.6711\n",
      "step 49700 of 50000: train_loss 1.6774, val loss 1.7036\n",
      "step 49800 of 50000: train_loss 1.6748, val loss 1.6776\n",
      "step 49900 of 50000: train_loss 1.6644, val loss 1.6620\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "87f7acec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T14:03:02.928139Z",
     "start_time": "2024-10-01T14:03:02.293230Z"
    }
   },
   "source": [
    "   \n",
    "model2.eval()\n",
    "inf = CausalInference(model=model2, device=device)\n",
    "\n",
    "int_nodes_vals0 = {'X1':np.array([0.0,])}\n",
    "int_nodes_vals1 = {'X1':np.array([1.0,])}\n",
    "effect_var = 'Y'\n",
    "effect_index = var_names2.index(effect_var)\n",
    "\n",
    "preds0 = inf.forward(all_data2, int_nodes_vals0)\n",
    "preds1 = inf.forward(all_data2, int_nodes_vals1)\n",
    "ATE_pred = (preds1[:,effect_index,:] - preds0[:,effect_index,:]).mean(0)\n",
    "eATE = np.abs(ATE_pred - ATE)\n",
    "print('ATE:', ATE, 'est ATE:', ATE_pred, 'error:', eATE)\n",
    "\n",
    "preds = model2(train_data.to(device))\n",
    "plt.scatter(train_data[:,effect_index,-1].detach().cpu().numpy(), preds[:, effect_index, -1].detach().cpu().numpy())\n",
    "print('Mean Squared Error Across All Vars:', ((train_data - preds.detach().cpu())**2).mean())\n",
    "print('Mean Squared Error Across Outcome:', ((train_data[:,effect_index,:] - preds[:,effect_index,:].detach().cpu())**2).mean())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE: [1.12] est ATE: [0.49129122] error: [0.62870878]\n",
      "Mean Squared Error Across All Vars: tensor(1.5402)\n",
      "Mean Squared Error Across Outcome: tensor(0.6690)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "a17b0cde",
   "metadata": {},
   "source": [
    "## Correct DAG"
   ]
  },
  {
   "cell_type": "code",
   "id": "6c8a281b",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-10-01T14:14:59.482444Z",
     "start_time": "2024-10-01T14:03:02.929159Z"
    }
   },
   "source": [
    "indices = np.arange(0, len(all_data3))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "val_inds = indices[:int(validation_fraction*len(indices))]\n",
    "train_inds = indices[int(validation_fraction*len(indices)):]\n",
    "train_data = all_data3[train_inds]\n",
    "val_data = all_data3[val_inds]\n",
    "train_data, val_data = torch.from_numpy(train_data).float(),  torch.from_numpy(val_data).float()\n",
    "\n",
    "input_dim = all_data3.shape[2]\n",
    "\n",
    "model3 = CaT(input_dim=input_dim,\n",
    "                    dropout_rate=dropout_rate,\n",
    "                    head_size=head_size,\n",
    "                    num_heads=num_heads,\n",
    "                    ff_n_embed=ff_n_embed,\n",
    "                    embed_dim= embed_dim,\n",
    "                    dag=DAGnx3,\n",
    "                    causal_ordering=causal_ordering3,\n",
    "                    n_layers=n_layers,\n",
    "                    device=device,\n",
    "                    var_types=var_types3, activation_function='Swish'\n",
    "                    ).to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model3.parameters(), lr=learning_rate)\n",
    "\n",
    "def get_batch(train_data, val_data, split, device, batch_size):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(0, len(data), (batch_size,))\n",
    "    x = data[ix]\n",
    "    return x.to(device)\n",
    "\n",
    "all_var_losses = {}\n",
    "for iter_ in range(0, max_iters):\n",
    "    # train and update the model\n",
    "    model3.train()\n",
    "\n",
    "    xb = get_batch(train_data=train_data, val_data=val_data, split='train', device=device, batch_size=batch_size)\n",
    "    xb_mod = torch.clone(xb.detach())\n",
    "    X, loss, loss_dict = model3(X=xb, targets=xb_mod)\n",
    "\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "    if iter_ % eval_interval == 0:  # evaluate the loss (no gradients)\n",
    "        for key in loss_dict.keys():\n",
    "            if key not in all_var_losses.keys():\n",
    "                all_var_losses[key] = []\n",
    "            all_var_losses[key].append(loss_dict[key])\n",
    "\n",
    "        model3.eval()\n",
    "        eval_loss = {}\n",
    "        for split in ['train', 'val']:\n",
    "            losses = torch.zeros(eval_iters)\n",
    "            for k in range(eval_iters):\n",
    "\n",
    "                xb = get_batch(train_data=train_data, val_data=val_data, split=split, device=device,\n",
    "                               batch_size=batch_size)\n",
    "                xb_mod = torch.clone(xb.detach())\n",
    "                X, loss, loss_dict = model3(X=xb, targets=xb_mod)\n",
    "                losses[k] = loss.item()\n",
    "            eval_loss[split] = losses.mean()\n",
    "        model3.train()\n",
    "        print(f\"step {iter_} of {max_iters}: train_loss {eval_loss['train']:.4f}, val loss {eval_loss['val']:.4f}\")\n",
    " "
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 of 50000: train_loss 6.3351, val loss 6.4850\n",
      "step 100 of 50000: train_loss 2.9934, val loss 2.9557\n",
      "step 200 of 50000: train_loss 3.0423, val loss 3.0331\n",
      "step 300 of 50000: train_loss 3.0441, val loss 3.0214\n",
      "step 400 of 50000: train_loss 3.0036, val loss 2.9910\n",
      "step 500 of 50000: train_loss 3.0132, val loss 3.0157\n",
      "step 600 of 50000: train_loss 3.0508, val loss 2.9956\n",
      "step 700 of 50000: train_loss 2.9881, val loss 2.9940\n",
      "step 800 of 50000: train_loss 3.0222, val loss 2.9891\n",
      "step 900 of 50000: train_loss 3.0391, val loss 3.0310\n",
      "step 1000 of 50000: train_loss 3.0679, val loss 2.9819\n",
      "step 1100 of 50000: train_loss 3.0196, val loss 2.9741\n",
      "step 1200 of 50000: train_loss 3.0208, val loss 3.0380\n",
      "step 1300 of 50000: train_loss 3.0300, val loss 2.9760\n",
      "step 1400 of 50000: train_loss 3.0023, val loss 3.0640\n",
      "step 1500 of 50000: train_loss 3.0481, val loss 2.9734\n",
      "step 1600 of 50000: train_loss 3.0580, val loss 2.9856\n",
      "step 1700 of 50000: train_loss 3.0054, val loss 2.9810\n",
      "step 1800 of 50000: train_loss 3.0153, val loss 2.9944\n",
      "step 1900 of 50000: train_loss 3.0552, val loss 3.0448\n",
      "step 2000 of 50000: train_loss 2.9936, val loss 3.0110\n",
      "step 2100 of 50000: train_loss 3.0920, val loss 2.9942\n",
      "step 2200 of 50000: train_loss 3.0102, val loss 2.9836\n",
      "step 2300 of 50000: train_loss 3.0002, val loss 2.9638\n",
      "step 2400 of 50000: train_loss 3.0182, val loss 2.9892\n",
      "step 2500 of 50000: train_loss 3.0328, val loss 3.0114\n",
      "step 2600 of 50000: train_loss 3.0061, val loss 2.9826\n",
      "step 2700 of 50000: train_loss 3.0118, val loss 3.0512\n",
      "step 2800 of 50000: train_loss 3.0612, val loss 2.9897\n",
      "step 2900 of 50000: train_loss 3.0362, val loss 3.0106\n",
      "step 3000 of 50000: train_loss 3.0403, val loss 3.0169\n",
      "step 3100 of 50000: train_loss 3.0348, val loss 2.9661\n",
      "step 3200 of 50000: train_loss 3.0501, val loss 2.9915\n",
      "step 3300 of 50000: train_loss 3.0593, val loss 3.0269\n",
      "step 3400 of 50000: train_loss 2.9959, val loss 2.9730\n",
      "step 3500 of 50000: train_loss 3.0432, val loss 2.9933\n",
      "step 3600 of 50000: train_loss 2.9770, val loss 2.9494\n",
      "step 3700 of 50000: train_loss 2.9708, val loss 2.9670\n",
      "step 3800 of 50000: train_loss 3.0274, val loss 2.9862\n",
      "step 3900 of 50000: train_loss 3.0229, val loss 3.0121\n",
      "step 4000 of 50000: train_loss 3.0234, val loss 2.9744\n",
      "step 4100 of 50000: train_loss 3.0490, val loss 3.0597\n",
      "step 4200 of 50000: train_loss 3.0186, val loss 2.9522\n",
      "step 4300 of 50000: train_loss 3.0410, val loss 2.9734\n",
      "step 4400 of 50000: train_loss 2.9924, val loss 3.0181\n",
      "step 4500 of 50000: train_loss 3.0415, val loss 2.9711\n",
      "step 4600 of 50000: train_loss 2.9824, val loss 2.9812\n",
      "step 4700 of 50000: train_loss 2.9788, val loss 2.9798\n",
      "step 4800 of 50000: train_loss 2.9959, val loss 2.9923\n",
      "step 4900 of 50000: train_loss 3.0596, val loss 3.0373\n",
      "step 5000 of 50000: train_loss 3.0354, val loss 3.0004\n",
      "step 5100 of 50000: train_loss 2.9668, val loss 2.9717\n",
      "step 5200 of 50000: train_loss 3.0129, val loss 2.9732\n",
      "step 5300 of 50000: train_loss 3.0084, val loss 2.9588\n",
      "step 5400 of 50000: train_loss 2.9890, val loss 2.9840\n",
      "step 5500 of 50000: train_loss 2.9871, val loss 2.9946\n",
      "step 5600 of 50000: train_loss 3.0036, val loss 2.9847\n",
      "step 5700 of 50000: train_loss 2.9973, val loss 2.9867\n",
      "step 5800 of 50000: train_loss 2.9907, val loss 3.0342\n",
      "step 5900 of 50000: train_loss 3.0522, val loss 3.0024\n",
      "step 6000 of 50000: train_loss 2.9961, val loss 2.9603\n",
      "step 6100 of 50000: train_loss 3.0573, val loss 2.9959\n",
      "step 6200 of 50000: train_loss 3.0023, val loss 2.9574\n",
      "step 6300 of 50000: train_loss 3.0082, val loss 3.0205\n",
      "step 6400 of 50000: train_loss 2.9969, val loss 2.9781\n",
      "step 6500 of 50000: train_loss 2.9959, val loss 2.9894\n",
      "step 6600 of 50000: train_loss 3.0041, val loss 3.0130\n",
      "step 6700 of 50000: train_loss 3.0286, val loss 3.0149\n",
      "step 6800 of 50000: train_loss 3.0922, val loss 3.0313\n",
      "step 6900 of 50000: train_loss 2.9978, val loss 2.9702\n",
      "step 7000 of 50000: train_loss 2.9880, val loss 2.9805\n",
      "step 7100 of 50000: train_loss 3.0280, val loss 2.9607\n",
      "step 7200 of 50000: train_loss 3.0134, val loss 2.9695\n",
      "step 7300 of 50000: train_loss 2.9802, val loss 3.0065\n",
      "step 7400 of 50000: train_loss 2.9703, val loss 2.9927\n",
      "step 7500 of 50000: train_loss 3.0040, val loss 2.9985\n",
      "step 7600 of 50000: train_loss 2.9681, val loss 2.9928\n",
      "step 7700 of 50000: train_loss 3.0325, val loss 2.9995\n",
      "step 7800 of 50000: train_loss 3.0145, val loss 2.9993\n",
      "step 7900 of 50000: train_loss 3.0224, val loss 2.9598\n",
      "step 8000 of 50000: train_loss 3.0216, val loss 2.9760\n",
      "step 8100 of 50000: train_loss 3.0514, val loss 2.9981\n",
      "step 8200 of 50000: train_loss 3.0203, val loss 2.9786\n",
      "step 8300 of 50000: train_loss 2.9922, val loss 3.0007\n",
      "step 8400 of 50000: train_loss 2.9982, val loss 3.0288\n",
      "step 8500 of 50000: train_loss 3.0473, val loss 2.9650\n",
      "step 8600 of 50000: train_loss 3.0006, val loss 3.0047\n",
      "step 8700 of 50000: train_loss 3.0210, val loss 2.9892\n",
      "step 8800 of 50000: train_loss 3.0010, val loss 2.9781\n",
      "step 8900 of 50000: train_loss 2.9986, val loss 2.9703\n",
      "step 9000 of 50000: train_loss 3.0504, val loss 3.0193\n",
      "step 9100 of 50000: train_loss 3.0220, val loss 3.0161\n",
      "step 9200 of 50000: train_loss 3.0166, val loss 3.0095\n",
      "step 9300 of 50000: train_loss 3.0248, val loss 2.9451\n",
      "step 9400 of 50000: train_loss 3.0594, val loss 2.9797\n",
      "step 9500 of 50000: train_loss 3.0389, val loss 3.0629\n",
      "step 9600 of 50000: train_loss 2.9920, val loss 2.9491\n",
      "step 9700 of 50000: train_loss 3.0202, val loss 2.9708\n",
      "step 9800 of 50000: train_loss 2.9985, val loss 2.9759\n",
      "step 9900 of 50000: train_loss 3.0486, val loss 2.9284\n",
      "step 10000 of 50000: train_loss 3.0393, val loss 3.0105\n",
      "step 10100 of 50000: train_loss 2.9653, val loss 2.9447\n",
      "step 10200 of 50000: train_loss 2.9814, val loss 2.9609\n",
      "step 10300 of 50000: train_loss 3.0704, val loss 3.0465\n",
      "step 10400 of 50000: train_loss 2.9996, val loss 2.9742\n",
      "step 10500 of 50000: train_loss 3.0298, val loss 2.9731\n",
      "step 10600 of 50000: train_loss 3.0176, val loss 3.0045\n",
      "step 10700 of 50000: train_loss 2.9896, val loss 2.9209\n",
      "step 10800 of 50000: train_loss 2.9577, val loss 2.9836\n",
      "step 10900 of 50000: train_loss 3.0132, val loss 2.9521\n",
      "step 11000 of 50000: train_loss 2.9787, val loss 3.0145\n",
      "step 11100 of 50000: train_loss 3.0011, val loss 2.9837\n",
      "step 11200 of 50000: train_loss 2.9850, val loss 3.0212\n",
      "step 11300 of 50000: train_loss 3.0476, val loss 2.9976\n",
      "step 11400 of 50000: train_loss 2.9623, val loss 3.0158\n",
      "step 11500 of 50000: train_loss 3.0207, val loss 2.9771\n",
      "step 11600 of 50000: train_loss 2.9947, val loss 2.9437\n",
      "step 11700 of 50000: train_loss 3.0433, val loss 2.9911\n",
      "step 11800 of 50000: train_loss 3.0147, val loss 3.0113\n",
      "step 11900 of 50000: train_loss 3.0610, val loss 2.9965\n",
      "step 12000 of 50000: train_loss 3.0288, val loss 3.0722\n",
      "step 12100 of 50000: train_loss 3.0158, val loss 2.9688\n",
      "step 12200 of 50000: train_loss 3.0560, val loss 2.9715\n",
      "step 12300 of 50000: train_loss 2.9829, val loss 2.9702\n",
      "step 12400 of 50000: train_loss 3.0258, val loss 2.9552\n",
      "step 12500 of 50000: train_loss 2.9330, val loss 3.0034\n",
      "step 12600 of 50000: train_loss 2.9994, val loss 3.0084\n",
      "step 12700 of 50000: train_loss 3.0318, val loss 2.9895\n",
      "step 12800 of 50000: train_loss 3.0199, val loss 3.0088\n",
      "step 12900 of 50000: train_loss 3.0294, val loss 2.9419\n",
      "step 13000 of 50000: train_loss 3.0029, val loss 2.9782\n",
      "step 13100 of 50000: train_loss 2.9845, val loss 2.9957\n",
      "step 13200 of 50000: train_loss 3.0163, val loss 3.0010\n",
      "step 13300 of 50000: train_loss 3.0107, val loss 2.9734\n",
      "step 13400 of 50000: train_loss 2.9958, val loss 2.9818\n",
      "step 13500 of 50000: train_loss 3.0137, val loss 2.9849\n",
      "step 13600 of 50000: train_loss 3.0335, val loss 2.9898\n",
      "step 13700 of 50000: train_loss 2.9655, val loss 2.9362\n",
      "step 13800 of 50000: train_loss 3.0623, val loss 2.9933\n",
      "step 13900 of 50000: train_loss 3.0421, val loss 2.9980\n",
      "step 14000 of 50000: train_loss 3.0075, val loss 3.0018\n",
      "step 14100 of 50000: train_loss 2.9914, val loss 2.9756\n",
      "step 14200 of 50000: train_loss 3.0607, val loss 2.9833\n",
      "step 14300 of 50000: train_loss 2.9856, val loss 3.0293\n",
      "step 14400 of 50000: train_loss 3.0323, val loss 3.0092\n",
      "step 14500 of 50000: train_loss 3.0386, val loss 2.9902\n",
      "step 14600 of 50000: train_loss 2.9435, val loss 2.9904\n",
      "step 14700 of 50000: train_loss 2.9771, val loss 2.9618\n",
      "step 14800 of 50000: train_loss 3.0253, val loss 2.9779\n",
      "step 14900 of 50000: train_loss 3.0124, val loss 3.0071\n",
      "step 15000 of 50000: train_loss 3.0387, val loss 3.0060\n",
      "step 15100 of 50000: train_loss 2.9907, val loss 2.9701\n",
      "step 15200 of 50000: train_loss 3.0367, val loss 2.9586\n",
      "step 15300 of 50000: train_loss 3.0207, val loss 2.9373\n",
      "step 15400 of 50000: train_loss 2.9940, val loss 2.9669\n",
      "step 15500 of 50000: train_loss 3.0196, val loss 2.9309\n",
      "step 15600 of 50000: train_loss 3.0126, val loss 2.9978\n",
      "step 15700 of 50000: train_loss 2.9926, val loss 2.9194\n",
      "step 15800 of 50000: train_loss 2.9681, val loss 2.9599\n",
      "step 15900 of 50000: train_loss 3.0337, val loss 2.9590\n",
      "step 16000 of 50000: train_loss 3.0463, val loss 3.0006\n",
      "step 16100 of 50000: train_loss 3.0176, val loss 2.9636\n",
      "step 16200 of 50000: train_loss 2.9876, val loss 2.9840\n",
      "step 16300 of 50000: train_loss 2.9984, val loss 2.9683\n",
      "step 16400 of 50000: train_loss 3.0506, val loss 2.9575\n",
      "step 16500 of 50000: train_loss 3.0239, val loss 3.0062\n",
      "step 16600 of 50000: train_loss 2.9809, val loss 3.0152\n",
      "step 16700 of 50000: train_loss 3.0104, val loss 2.9591\n",
      "step 16800 of 50000: train_loss 3.0081, val loss 2.9908\n",
      "step 16900 of 50000: train_loss 2.9927, val loss 2.9361\n",
      "step 17000 of 50000: train_loss 3.0005, val loss 2.9883\n",
      "step 17100 of 50000: train_loss 3.0333, val loss 2.9850\n",
      "step 17200 of 50000: train_loss 2.9952, val loss 2.9473\n",
      "step 17300 of 50000: train_loss 3.0310, val loss 2.9868\n",
      "step 17400 of 50000: train_loss 2.9787, val loss 3.0065\n",
      "step 17500 of 50000: train_loss 3.0236, val loss 2.9785\n",
      "step 17600 of 50000: train_loss 3.0016, val loss 3.0088\n",
      "step 17700 of 50000: train_loss 3.0135, val loss 2.9665\n",
      "step 17800 of 50000: train_loss 2.9963, val loss 2.9980\n",
      "step 17900 of 50000: train_loss 2.9879, val loss 2.9554\n",
      "step 18000 of 50000: train_loss 3.0045, val loss 3.0138\n",
      "step 18100 of 50000: train_loss 2.9970, val loss 3.0131\n",
      "step 18200 of 50000: train_loss 3.0082, val loss 2.9547\n",
      "step 18300 of 50000: train_loss 3.0394, val loss 3.0113\n",
      "step 18400 of 50000: train_loss 2.9986, val loss 2.9783\n",
      "step 18500 of 50000: train_loss 2.9855, val loss 3.0036\n",
      "step 18600 of 50000: train_loss 2.9712, val loss 3.0193\n",
      "step 18700 of 50000: train_loss 3.0262, val loss 3.0297\n",
      "step 18800 of 50000: train_loss 3.0070, val loss 2.9890\n",
      "step 18900 of 50000: train_loss 3.0311, val loss 3.0122\n",
      "step 19000 of 50000: train_loss 3.0519, val loss 2.9830\n",
      "step 19100 of 50000: train_loss 2.9943, val loss 3.0359\n",
      "step 19200 of 50000: train_loss 2.9962, val loss 2.9675\n",
      "step 19300 of 50000: train_loss 3.0371, val loss 2.9642\n",
      "step 19400 of 50000: train_loss 3.0109, val loss 2.9941\n",
      "step 19500 of 50000: train_loss 3.0036, val loss 2.9932\n",
      "step 19600 of 50000: train_loss 3.0587, val loss 2.9975\n",
      "step 19700 of 50000: train_loss 3.0145, val loss 2.9650\n",
      "step 19800 of 50000: train_loss 3.0292, val loss 2.9888\n",
      "step 19900 of 50000: train_loss 3.0729, val loss 3.0064\n",
      "step 20000 of 50000: train_loss 2.9991, val loss 2.9667\n",
      "step 20100 of 50000: train_loss 2.9947, val loss 3.0134\n",
      "step 20200 of 50000: train_loss 2.9839, val loss 2.9491\n",
      "step 20300 of 50000: train_loss 3.0091, val loss 2.9807\n",
      "step 20400 of 50000: train_loss 3.0433, val loss 2.9872\n",
      "step 20500 of 50000: train_loss 3.0023, val loss 2.9691\n",
      "step 20600 of 50000: train_loss 2.9916, val loss 2.9938\n",
      "step 20700 of 50000: train_loss 2.9636, val loss 3.0320\n",
      "step 20800 of 50000: train_loss 3.0286, val loss 2.9552\n",
      "step 20900 of 50000: train_loss 3.0156, val loss 2.9842\n",
      "step 21000 of 50000: train_loss 2.9693, val loss 2.9692\n",
      "step 21100 of 50000: train_loss 3.0151, val loss 2.9783\n",
      "step 21200 of 50000: train_loss 3.0067, val loss 2.9871\n",
      "step 21300 of 50000: train_loss 2.9857, val loss 2.9659\n",
      "step 21400 of 50000: train_loss 2.9952, val loss 3.0092\n",
      "step 21500 of 50000: train_loss 3.0019, val loss 2.9588\n",
      "step 21600 of 50000: train_loss 3.0091, val loss 3.0151\n",
      "step 21700 of 50000: train_loss 2.9884, val loss 2.9818\n",
      "step 21800 of 50000: train_loss 3.0204, val loss 2.9779\n",
      "step 21900 of 50000: train_loss 3.0166, val loss 2.9368\n",
      "step 22000 of 50000: train_loss 3.0109, val loss 3.0332\n",
      "step 22100 of 50000: train_loss 2.9600, val loss 2.9794\n",
      "step 22200 of 50000: train_loss 3.0133, val loss 2.9729\n",
      "step 22300 of 50000: train_loss 2.9913, val loss 3.0036\n",
      "step 22400 of 50000: train_loss 3.0204, val loss 2.9863\n",
      "step 22500 of 50000: train_loss 2.9766, val loss 2.9966\n",
      "step 22600 of 50000: train_loss 3.0055, val loss 2.9986\n",
      "step 22700 of 50000: train_loss 3.0270, val loss 3.0139\n",
      "step 22800 of 50000: train_loss 2.9766, val loss 2.9646\n",
      "step 22900 of 50000: train_loss 3.0107, val loss 2.9683\n",
      "step 23000 of 50000: train_loss 3.0087, val loss 3.0083\n",
      "step 23100 of 50000: train_loss 3.0572, val loss 2.9809\n",
      "step 23200 of 50000: train_loss 3.0303, val loss 3.0018\n",
      "step 23300 of 50000: train_loss 3.0090, val loss 2.9526\n",
      "step 23400 of 50000: train_loss 2.9839, val loss 2.9890\n",
      "step 23500 of 50000: train_loss 2.9848, val loss 2.9680\n",
      "step 23600 of 50000: train_loss 2.9883, val loss 2.9647\n",
      "step 23700 of 50000: train_loss 3.0318, val loss 2.9972\n",
      "step 23800 of 50000: train_loss 3.0673, val loss 3.0006\n",
      "step 23900 of 50000: train_loss 3.0133, val loss 2.9622\n",
      "step 24000 of 50000: train_loss 3.0217, val loss 2.9763\n",
      "step 24100 of 50000: train_loss 2.9919, val loss 3.0359\n",
      "step 24200 of 50000: train_loss 3.0294, val loss 2.9839\n",
      "step 24300 of 50000: train_loss 3.0083, val loss 2.9682\n",
      "step 24400 of 50000: train_loss 3.0256, val loss 2.9969\n",
      "step 24500 of 50000: train_loss 3.0152, val loss 2.9344\n",
      "step 24600 of 50000: train_loss 2.9869, val loss 2.9737\n",
      "step 24700 of 50000: train_loss 3.0160, val loss 3.0175\n",
      "step 24800 of 50000: train_loss 3.0121, val loss 2.9608\n",
      "step 24900 of 50000: train_loss 3.0085, val loss 2.9377\n",
      "step 25000 of 50000: train_loss 3.0039, val loss 2.9955\n",
      "step 25100 of 50000: train_loss 3.0525, val loss 2.9913\n",
      "step 25200 of 50000: train_loss 3.0370, val loss 3.0015\n",
      "step 25300 of 50000: train_loss 3.0151, val loss 3.0235\n",
      "step 25400 of 50000: train_loss 3.0256, val loss 2.9545\n",
      "step 25500 of 50000: train_loss 2.9942, val loss 2.9504\n",
      "step 25600 of 50000: train_loss 2.9803, val loss 2.9746\n",
      "step 25700 of 50000: train_loss 3.0333, val loss 3.0196\n",
      "step 25800 of 50000: train_loss 3.0106, val loss 3.0083\n",
      "step 25900 of 50000: train_loss 3.0092, val loss 2.9647\n",
      "step 26000 of 50000: train_loss 3.0223, val loss 3.0081\n",
      "step 26100 of 50000: train_loss 3.0024, val loss 2.9664\n",
      "step 26200 of 50000: train_loss 3.0469, val loss 3.0043\n",
      "step 26300 of 50000: train_loss 3.0742, val loss 3.0131\n",
      "step 26400 of 50000: train_loss 2.9959, val loss 2.9549\n",
      "step 26500 of 50000: train_loss 2.9923, val loss 2.9941\n",
      "step 26600 of 50000: train_loss 3.0103, val loss 3.0026\n",
      "step 26700 of 50000: train_loss 3.0149, val loss 2.9846\n",
      "step 26800 of 50000: train_loss 2.9681, val loss 2.9893\n",
      "step 26900 of 50000: train_loss 2.9899, val loss 2.9783\n",
      "step 27000 of 50000: train_loss 2.9928, val loss 2.9851\n",
      "step 27100 of 50000: train_loss 3.0175, val loss 2.9952\n",
      "step 27200 of 50000: train_loss 3.0461, val loss 2.9773\n",
      "step 27300 of 50000: train_loss 3.0039, val loss 2.9895\n",
      "step 27400 of 50000: train_loss 3.0524, val loss 3.0107\n",
      "step 27500 of 50000: train_loss 2.9464, val loss 2.9460\n",
      "step 27600 of 50000: train_loss 2.9941, val loss 2.9828\n",
      "step 27700 of 50000: train_loss 2.9741, val loss 2.9904\n",
      "step 27800 of 50000: train_loss 2.9775, val loss 2.9664\n",
      "step 27900 of 50000: train_loss 2.9768, val loss 2.9864\n",
      "step 28000 of 50000: train_loss 3.0143, val loss 2.9522\n",
      "step 28100 of 50000: train_loss 3.0296, val loss 2.9769\n",
      "step 28200 of 50000: train_loss 3.0624, val loss 2.9812\n",
      "step 28300 of 50000: train_loss 2.9936, val loss 2.9978\n",
      "step 28400 of 50000: train_loss 3.0179, val loss 2.9761\n",
      "step 28500 of 50000: train_loss 2.9963, val loss 2.9943\n",
      "step 28600 of 50000: train_loss 3.0288, val loss 2.9588\n",
      "step 28700 of 50000: train_loss 2.9824, val loss 2.9738\n",
      "step 28800 of 50000: train_loss 2.9900, val loss 2.9589\n",
      "step 28900 of 50000: train_loss 2.9701, val loss 2.9925\n",
      "step 29000 of 50000: train_loss 3.0327, val loss 2.9637\n",
      "step 29100 of 50000: train_loss 3.0201, val loss 2.9629\n",
      "step 29200 of 50000: train_loss 3.0043, val loss 2.9641\n",
      "step 29300 of 50000: train_loss 2.9914, val loss 2.9929\n",
      "step 29400 of 50000: train_loss 3.0160, val loss 3.0051\n",
      "step 29500 of 50000: train_loss 3.0087, val loss 2.9892\n",
      "step 29600 of 50000: train_loss 3.0231, val loss 2.9821\n",
      "step 29700 of 50000: train_loss 3.0167, val loss 2.9893\n",
      "step 29800 of 50000: train_loss 3.0405, val loss 2.9700\n",
      "step 29900 of 50000: train_loss 3.0736, val loss 2.9763\n",
      "step 30000 of 50000: train_loss 3.0084, val loss 2.9822\n",
      "step 30100 of 50000: train_loss 2.9813, val loss 2.9756\n",
      "step 30200 of 50000: train_loss 3.0494, val loss 3.0450\n",
      "step 30300 of 50000: train_loss 2.9947, val loss 2.9814\n",
      "step 30400 of 50000: train_loss 3.0220, val loss 2.9484\n",
      "step 30500 of 50000: train_loss 2.9565, val loss 2.9672\n",
      "step 30600 of 50000: train_loss 2.9991, val loss 3.0163\n",
      "step 30700 of 50000: train_loss 2.9844, val loss 3.0196\n",
      "step 30800 of 50000: train_loss 2.9782, val loss 2.9673\n",
      "step 30900 of 50000: train_loss 3.0577, val loss 2.9852\n",
      "step 31000 of 50000: train_loss 3.0050, val loss 2.9621\n",
      "step 31100 of 50000: train_loss 3.0351, val loss 3.0028\n",
      "step 31200 of 50000: train_loss 3.0195, val loss 2.9528\n",
      "step 31300 of 50000: train_loss 3.0354, val loss 2.9763\n",
      "step 31400 of 50000: train_loss 2.9546, val loss 2.9640\n",
      "step 31500 of 50000: train_loss 3.0057, val loss 3.0009\n",
      "step 31600 of 50000: train_loss 2.9726, val loss 2.9407\n",
      "step 31700 of 50000: train_loss 2.9793, val loss 2.9570\n",
      "step 31800 of 50000: train_loss 3.0057, val loss 2.9648\n",
      "step 31900 of 50000: train_loss 3.0744, val loss 3.0205\n",
      "step 32000 of 50000: train_loss 2.9717, val loss 2.9944\n",
      "step 32100 of 50000: train_loss 2.9948, val loss 2.9817\n",
      "step 32200 of 50000: train_loss 2.9908, val loss 2.9832\n",
      "step 32300 of 50000: train_loss 3.0328, val loss 2.9513\n",
      "step 32400 of 50000: train_loss 2.9874, val loss 2.9739\n",
      "step 32500 of 50000: train_loss 2.9975, val loss 2.9558\n",
      "step 32600 of 50000: train_loss 2.9603, val loss 2.9752\n",
      "step 32700 of 50000: train_loss 2.9487, val loss 2.9673\n",
      "step 32800 of 50000: train_loss 3.0523, val loss 2.9997\n",
      "step 32900 of 50000: train_loss 3.0140, val loss 2.9720\n",
      "step 33000 of 50000: train_loss 3.0757, val loss 3.0137\n",
      "step 33100 of 50000: train_loss 3.0208, val loss 3.0172\n",
      "step 33200 of 50000: train_loss 3.0370, val loss 2.9346\n",
      "step 33300 of 50000: train_loss 2.9700, val loss 2.9401\n",
      "step 33400 of 50000: train_loss 3.0571, val loss 2.9296\n",
      "step 33500 of 50000: train_loss 2.9968, val loss 2.9408\n",
      "step 33600 of 50000: train_loss 2.9719, val loss 2.9577\n",
      "step 33700 of 50000: train_loss 3.0220, val loss 2.9433\n",
      "step 33800 of 50000: train_loss 2.9934, val loss 2.9699\n",
      "step 33900 of 50000: train_loss 3.0229, val loss 2.9644\n",
      "step 34000 of 50000: train_loss 3.0220, val loss 2.9750\n",
      "step 34100 of 50000: train_loss 3.0309, val loss 2.9892\n",
      "step 34200 of 50000: train_loss 3.0448, val loss 2.9993\n",
      "step 34300 of 50000: train_loss 2.9990, val loss 2.9883\n",
      "step 34400 of 50000: train_loss 2.9770, val loss 3.0188\n",
      "step 34500 of 50000: train_loss 2.9852, val loss 2.9793\n",
      "step 34600 of 50000: train_loss 3.0220, val loss 3.0092\n",
      "step 34700 of 50000: train_loss 2.9995, val loss 2.9424\n",
      "step 34800 of 50000: train_loss 2.9936, val loss 2.9797\n",
      "step 34900 of 50000: train_loss 3.0229, val loss 2.9903\n",
      "step 35000 of 50000: train_loss 3.0576, val loss 3.0220\n",
      "step 35100 of 50000: train_loss 3.0162, val loss 2.9714\n",
      "step 35200 of 50000: train_loss 2.9759, val loss 2.9722\n",
      "step 35300 of 50000: train_loss 2.9779, val loss 2.9541\n",
      "step 35400 of 50000: train_loss 3.0506, val loss 2.9879\n",
      "step 35500 of 50000: train_loss 3.0056, val loss 2.9616\n",
      "step 35600 of 50000: train_loss 3.0018, val loss 2.9487\n",
      "step 35700 of 50000: train_loss 3.0311, val loss 2.9962\n",
      "step 35800 of 50000: train_loss 2.9851, val loss 2.9992\n",
      "step 35900 of 50000: train_loss 3.0069, val loss 2.9673\n",
      "step 36000 of 50000: train_loss 3.0071, val loss 3.0365\n",
      "step 36100 of 50000: train_loss 3.0297, val loss 2.9467\n",
      "step 36200 of 50000: train_loss 3.0020, val loss 2.9875\n",
      "step 36300 of 50000: train_loss 3.0190, val loss 2.9850\n",
      "step 36400 of 50000: train_loss 2.9920, val loss 2.9558\n",
      "step 36500 of 50000: train_loss 3.0080, val loss 2.9691\n",
      "step 36600 of 50000: train_loss 3.0106, val loss 2.9678\n",
      "step 36700 of 50000: train_loss 2.9959, val loss 2.9796\n",
      "step 36800 of 50000: train_loss 3.0429, val loss 2.9401\n",
      "step 36900 of 50000: train_loss 3.0217, val loss 2.9828\n",
      "step 37000 of 50000: train_loss 3.0409, val loss 2.9912\n",
      "step 37100 of 50000: train_loss 3.0530, val loss 2.9975\n",
      "step 37200 of 50000: train_loss 3.0339, val loss 2.9421\n",
      "step 37300 of 50000: train_loss 2.9818, val loss 3.0029\n",
      "step 37400 of 50000: train_loss 3.0053, val loss 2.9689\n",
      "step 37500 of 50000: train_loss 2.9920, val loss 2.9686\n",
      "step 37600 of 50000: train_loss 3.0288, val loss 3.0217\n",
      "step 37700 of 50000: train_loss 2.9870, val loss 2.9580\n",
      "step 37800 of 50000: train_loss 3.0040, val loss 2.9682\n",
      "step 37900 of 50000: train_loss 3.0148, val loss 2.9537\n",
      "step 38000 of 50000: train_loss 2.9469, val loss 2.9940\n",
      "step 38100 of 50000: train_loss 3.0516, val loss 2.9521\n",
      "step 38200 of 50000: train_loss 2.9905, val loss 2.9500\n",
      "step 38300 of 50000: train_loss 3.0111, val loss 2.9550\n",
      "step 38400 of 50000: train_loss 3.0415, val loss 3.0169\n",
      "step 38500 of 50000: train_loss 2.9570, val loss 2.9287\n",
      "step 38600 of 50000: train_loss 3.0021, val loss 2.9900\n",
      "step 38700 of 50000: train_loss 2.9582, val loss 2.9904\n",
      "step 38800 of 50000: train_loss 3.0400, val loss 2.9951\n",
      "step 38900 of 50000: train_loss 2.9824, val loss 2.9910\n",
      "step 39000 of 50000: train_loss 3.0083, val loss 2.9949\n",
      "step 39100 of 50000: train_loss 3.0228, val loss 2.9968\n",
      "step 39200 of 50000: train_loss 2.9771, val loss 3.0026\n",
      "step 39300 of 50000: train_loss 3.0104, val loss 2.9391\n",
      "step 39400 of 50000: train_loss 2.9969, val loss 2.9517\n",
      "step 39500 of 50000: train_loss 3.0507, val loss 3.0118\n",
      "step 39600 of 50000: train_loss 3.0113, val loss 2.9749\n",
      "step 39700 of 50000: train_loss 3.0175, val loss 3.0006\n",
      "step 39800 of 50000: train_loss 3.0091, val loss 2.9636\n",
      "step 39900 of 50000: train_loss 2.9967, val loss 3.0029\n",
      "step 40000 of 50000: train_loss 3.0241, val loss 2.9689\n",
      "step 40100 of 50000: train_loss 2.9864, val loss 2.9781\n",
      "step 40200 of 50000: train_loss 3.0435, val loss 2.9965\n",
      "step 40300 of 50000: train_loss 3.0056, val loss 2.9625\n",
      "step 40400 of 50000: train_loss 3.0373, val loss 2.9825\n",
      "step 40500 of 50000: train_loss 3.0298, val loss 2.9726\n",
      "step 40600 of 50000: train_loss 3.0243, val loss 2.9878\n",
      "step 40700 of 50000: train_loss 3.0234, val loss 3.0131\n",
      "step 40800 of 50000: train_loss 2.9710, val loss 3.0046\n",
      "step 40900 of 50000: train_loss 3.0216, val loss 2.9595\n",
      "step 41000 of 50000: train_loss 3.0161, val loss 2.9958\n",
      "step 41100 of 50000: train_loss 3.0219, val loss 2.9603\n",
      "step 41200 of 50000: train_loss 3.0052, val loss 2.9735\n",
      "step 41300 of 50000: train_loss 2.9875, val loss 2.9683\n",
      "step 41400 of 50000: train_loss 3.0550, val loss 2.9413\n",
      "step 41500 of 50000: train_loss 3.0212, val loss 2.9396\n",
      "step 41600 of 50000: train_loss 3.0004, val loss 2.9845\n",
      "step 41700 of 50000: train_loss 2.9878, val loss 2.9843\n",
      "step 41800 of 50000: train_loss 3.0347, val loss 2.9845\n",
      "step 41900 of 50000: train_loss 3.0751, val loss 3.0271\n",
      "step 42000 of 50000: train_loss 3.0479, val loss 2.9828\n",
      "step 42100 of 50000: train_loss 3.0215, val loss 2.9979\n",
      "step 42200 of 50000: train_loss 3.0423, val loss 3.0212\n",
      "step 42300 of 50000: train_loss 2.9962, val loss 2.9535\n",
      "step 42400 of 50000: train_loss 2.9734, val loss 2.9829\n",
      "step 42500 of 50000: train_loss 3.0599, val loss 2.9757\n",
      "step 42600 of 50000: train_loss 3.0320, val loss 2.9935\n",
      "step 42700 of 50000: train_loss 3.0231, val loss 2.9230\n",
      "step 42800 of 50000: train_loss 3.0737, val loss 2.9861\n",
      "step 42900 of 50000: train_loss 3.0317, val loss 2.9515\n",
      "step 43000 of 50000: train_loss 3.0650, val loss 2.9499\n",
      "step 43100 of 50000: train_loss 3.0148, val loss 3.0190\n",
      "step 43200 of 50000: train_loss 3.0091, val loss 2.9797\n",
      "step 43300 of 50000: train_loss 3.0337, val loss 2.9986\n",
      "step 43400 of 50000: train_loss 2.9728, val loss 2.9564\n",
      "step 43500 of 50000: train_loss 2.9748, val loss 3.0028\n",
      "step 43600 of 50000: train_loss 3.0510, val loss 2.9854\n",
      "step 43700 of 50000: train_loss 2.9766, val loss 2.9709\n",
      "step 43800 of 50000: train_loss 3.0433, val loss 3.0211\n",
      "step 43900 of 50000: train_loss 2.9794, val loss 2.9690\n",
      "step 44000 of 50000: train_loss 2.9696, val loss 2.9490\n",
      "step 44100 of 50000: train_loss 2.9782, val loss 3.0097\n",
      "step 44200 of 50000: train_loss 3.0138, val loss 2.9848\n",
      "step 44300 of 50000: train_loss 3.0061, val loss 2.9894\n",
      "step 44400 of 50000: train_loss 3.0359, val loss 2.9445\n",
      "step 44500 of 50000: train_loss 3.0285, val loss 2.9835\n",
      "step 44600 of 50000: train_loss 2.9853, val loss 2.9484\n",
      "step 44700 of 50000: train_loss 3.0265, val loss 3.0102\n",
      "step 44800 of 50000: train_loss 2.9524, val loss 3.0021\n",
      "step 44900 of 50000: train_loss 3.0037, val loss 3.0299\n",
      "step 45000 of 50000: train_loss 3.0226, val loss 2.9963\n",
      "step 45100 of 50000: train_loss 3.0223, val loss 2.9931\n",
      "step 45200 of 50000: train_loss 3.0138, val loss 3.0051\n",
      "step 45300 of 50000: train_loss 2.9930, val loss 2.9868\n",
      "step 45400 of 50000: train_loss 2.9926, val loss 2.9896\n",
      "step 45500 of 50000: train_loss 3.0099, val loss 2.9893\n",
      "step 45600 of 50000: train_loss 3.0023, val loss 2.9558\n",
      "step 45700 of 50000: train_loss 3.0008, val loss 3.0692\n",
      "step 45800 of 50000: train_loss 2.9746, val loss 3.0025\n",
      "step 45900 of 50000: train_loss 2.9592, val loss 2.9807\n",
      "step 46000 of 50000: train_loss 3.0040, val loss 2.9660\n",
      "step 46100 of 50000: train_loss 2.9851, val loss 2.9430\n",
      "step 46200 of 50000: train_loss 2.9793, val loss 2.9528\n",
      "step 46300 of 50000: train_loss 3.0518, val loss 2.9774\n",
      "step 46400 of 50000: train_loss 3.0302, val loss 3.0072\n",
      "step 46500 of 50000: train_loss 3.0101, val loss 2.9736\n",
      "step 46600 of 50000: train_loss 2.9696, val loss 2.9288\n",
      "step 46700 of 50000: train_loss 3.0080, val loss 2.9927\n",
      "step 46800 of 50000: train_loss 2.9712, val loss 2.9613\n",
      "step 46900 of 50000: train_loss 2.9860, val loss 3.0036\n",
      "step 47000 of 50000: train_loss 3.0155, val loss 2.9549\n",
      "step 47100 of 50000: train_loss 3.0510, val loss 2.9447\n",
      "step 47200 of 50000: train_loss 3.0098, val loss 2.9858\n",
      "step 47300 of 50000: train_loss 3.0013, val loss 2.9673\n",
      "step 47400 of 50000: train_loss 2.9980, val loss 2.9800\n",
      "step 47500 of 50000: train_loss 3.0505, val loss 2.9409\n",
      "step 47600 of 50000: train_loss 2.9885, val loss 2.9858\n",
      "step 47700 of 50000: train_loss 2.9809, val loss 2.9937\n",
      "step 47800 of 50000: train_loss 3.0057, val loss 2.9588\n",
      "step 47900 of 50000: train_loss 3.0249, val loss 2.9258\n",
      "step 48000 of 50000: train_loss 2.9894, val loss 2.9196\n",
      "step 48100 of 50000: train_loss 2.9762, val loss 2.9384\n",
      "step 48200 of 50000: train_loss 3.0247, val loss 2.9219\n",
      "step 48300 of 50000: train_loss 2.9682, val loss 2.9844\n",
      "step 48400 of 50000: train_loss 3.0114, val loss 3.0278\n",
      "step 48500 of 50000: train_loss 2.9966, val loss 3.0412\n",
      "step 48600 of 50000: train_loss 2.9809, val loss 2.9805\n",
      "step 48700 of 50000: train_loss 2.9829, val loss 2.9532\n",
      "step 48800 of 50000: train_loss 2.9983, val loss 3.0025\n",
      "step 48900 of 50000: train_loss 3.0183, val loss 2.9566\n",
      "step 49000 of 50000: train_loss 3.0431, val loss 2.9820\n",
      "step 49100 of 50000: train_loss 3.0428, val loss 2.9517\n",
      "step 49200 of 50000: train_loss 3.0080, val loss 2.9772\n",
      "step 49300 of 50000: train_loss 3.0215, val loss 2.9424\n",
      "step 49400 of 50000: train_loss 2.9502, val loss 3.0037\n",
      "step 49500 of 50000: train_loss 2.9984, val loss 2.9508\n",
      "step 49600 of 50000: train_loss 3.0171, val loss 3.0236\n",
      "step 49700 of 50000: train_loss 2.9664, val loss 2.9703\n",
      "step 49800 of 50000: train_loss 2.9946, val loss 2.9504\n",
      "step 49900 of 50000: train_loss 2.9766, val loss 2.9641\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "6057349c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T14:15:00.106818Z",
     "start_time": "2024-10-01T14:14:59.483381Z"
    }
   },
   "source": [
    "   \n",
    "model3.eval()\n",
    "inf = CausalInference(model=model3, device=device)\n",
    "\n",
    "int_nodes_vals0 = {'X1':np.array([0.0,])}\n",
    "int_nodes_vals1 = {'X1':np.array([1.0,])}\n",
    "effect_var = 'Y'\n",
    "effect_index = var_names3.index(effect_var)\n",
    "\n",
    "preds0 = inf.forward(all_data3, int_nodes_vals0)\n",
    "preds1 = inf.forward(all_data3, int_nodes_vals1)\n",
    "ATE_pred = (preds1[:,effect_index,:] - preds0[:,effect_index,:]).mean(0)\n",
    "eATE = np.abs(ATE_pred - ATE)\n",
    "print('ATE:', ATE, 'est ATE:', ATE_pred, 'error:', eATE)\n",
    "\n",
    "preds = model3(train_data.to(device))\n",
    "plt.scatter(train_data[:,effect_index,-1].detach().cpu().numpy(), preds[:, effect_index, -1].detach().cpu().numpy())\n",
    "print('Mean Squared Error Across All Vars:', ((train_data - preds.detach().cpu())**2).mean())\n",
    "print('Mean Squared Error Across Outcome:', ((train_data[:,effect_index,:] - preds[:,effect_index,:].detach().cpu())**2).mean())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE: [1.12] est ATE: [1.1106011] error: [0.0093989]\n",
      "Mean Squared Error Across All Vars: tensor(1.0026)\n",
      "Mean Squared Error Across Outcome: tensor(0.9941)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "1565ba79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T14:15:00.109460Z",
     "start_time": "2024-10-01T14:15:00.107728Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "8ae93b5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T14:15:00.111772Z",
     "start_time": "2024-10-01T14:15:00.110277Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "275cb210",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T14:15:00.114158Z",
     "start_time": "2024-10-01T14:15:00.112569Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "2f71483b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T14:15:00.117490Z",
     "start_time": "2024-10-01T14:15:00.115735Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "7a705d07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T14:15:00.120287Z",
     "start_time": "2024-10-01T14:15:00.118477Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "d89844f5-04ea-41cd-b38b-38a6cae4162b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T14:15:00.122905Z",
     "start_time": "2024-10-01T14:15:00.121233Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
