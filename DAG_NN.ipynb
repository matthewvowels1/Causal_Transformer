{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d3c7e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4ae73a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2b317c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ada67fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_masks(adjacency_matrix, neurons_per_layer):\n",
    "#     num_layers = len(neurons_per_layer)\n",
    "#     num_nodes = adjacency_matrix.shape[0]\n",
    "#     layer_masks = []\n",
    "\n",
    "#     # Ensure each layer, except the last, has an even number of neurons if required\n",
    "#     assert all(n % 2 == 0 for n in neurons_per_layer[:-1]), \"Each layer, except the last, must have an even number of neurons.\"\n",
    "\n",
    "#     # The last layer must match the number of DAG nodes (variables)\n",
    "#     assert neurons_per_layer[-1] == num_nodes, \"The last layer must exactly match the number of nodes in the DAG.\"\n",
    "\n",
    "#     for layer_index in range(1, num_layers):\n",
    "#         prev_layer_size = neurons_per_layer[layer_index - 1]\n",
    "#         curr_layer_size = neurons_per_layer[layer_index]\n",
    "#         mask = np.zeros((curr_layer_size, prev_layer_size))\n",
    "\n",
    "#         prev_neurons_per_node = prev_layer_size // num_nodes\n",
    "#         curr_neurons_per_node = curr_layer_size // num_nodes\n",
    "\n",
    "#         for i in range(num_nodes):\n",
    "#             for j in range(num_nodes):\n",
    "#                 if adjacency_matrix[i, j] == 1:\n",
    "#                     mask[j * curr_neurons_per_node:(j + 1) * curr_neurons_per_node,\n",
    "#                          i * prev_neurons_per_node:(i + 1) * prev_neurons_per_node] = 1\n",
    "#         layer_masks.append(mask)\n",
    "\n",
    "#     return layer_masks\n",
    "\n",
    "\n",
    "def create_masks(adjacency_matrix, neurons_per_layer):\n",
    "    num_layers = len(neurons_per_layer)\n",
    "    num_nodes = adjacency_matrix.shape[0]\n",
    "    layer_masks = []\n",
    "\n",
    "    # Create masks for each layer based on the adjacency matrix and the idea of preserving the diagonal after the first layer.\n",
    "    for layer_index in range(1, num_layers):\n",
    "        prev_layer_size = neurons_per_layer[layer_index - 1]\n",
    "        curr_layer_size = neurons_per_layer[layer_index]\n",
    "        mask = np.zeros((curr_layer_size, prev_layer_size))\n",
    "\n",
    "        # Process each node according to the adjacency matrix for the first layer\n",
    "        if layer_index == 1:\n",
    "            for i in range(num_nodes):\n",
    "                for j in range(num_nodes):\n",
    "                    if adjacency_matrix[i, j] == 1:\n",
    "                        mask[j, i] = 1  # Allow signal as per adjacency matrix\n",
    "        else:\n",
    "            # After the first layer, maintain diagonal connectivity to ensure signal preservation\n",
    "            # and also allow propagation according to the adjacency matrix logic\n",
    "            np.fill_diagonal(mask, 1)  # Ensure self-preservation\n",
    "            for i in range(min(num_nodes, prev_layer_size)):  # Keep within the smaller dimension\n",
    "                for j in range(num_nodes):\n",
    "                    if adjacency_matrix[i, j] == 1:\n",
    "                        mask[j, i] = 1  # Propagate based on adjacency rules\n",
    "\n",
    "        layer_masks.append(mask)\n",
    "\n",
    "    return layer_masks\n",
    "\n",
    "\n",
    "class MaskedLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(MaskedLinear, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = nn.Parameter(torch.Tensor(out_features, in_features))\n",
    "        self.bias = nn.Parameter(torch.zeros(out_features))\n",
    "        self.mask = None\n",
    "        self.reset_parameters()\n",
    "    \n",
    "    def set_mask(self, mask):\n",
    "        self.mask = nn.Parameter(mask, requires_grad=False)\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "#         nn.init.kaiming_uniform_(self.weight, a=np.sqrt(5))\n",
    "        self.weight.data.fill_(1.0)\n",
    "        self.bias.data.fill_(0.0)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        if self.mask is not None:\n",
    "            return nn.functional.linear(input, self.weight * self.mask)\n",
    "        else:\n",
    "            return nn.functional.linear(input, self.weight)\n",
    "    \n",
    "    \n",
    "class DAGAutoencoder(nn.Module):\n",
    "    def __init__(self, neurons_per_layer):\n",
    "        super(DAGAutoencoder, self).__init__()\n",
    "        self.layers = nn.ModuleList() \n",
    "        self.activations = nn.ModuleList()  \n",
    "\n",
    "        for i in range(len(neurons_per_layer) - 1):\n",
    "            linear_layer = MaskedLinear(neurons_per_layer[i], neurons_per_layer[i+1])\n",
    "            self.layers.append(linear_layer)\n",
    "            if i < len(neurons_per_layer) - 2:  \n",
    "                self.activations.append(nn.ReLU())\n",
    "\n",
    "    def set_masks(self, masks):\n",
    "        # Apply masks only to linear layers\n",
    "        assert len(masks) == len(self.layers), \"The number of masks must match the number of linear layers.\"\n",
    "        for layer, mask in zip(self.layers, masks):\n",
    "            layer.set_mask(mask)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        for linear, activation in zip(self.layers, self.activations):\n",
    "            x = linear(x)\n",
    "            x = activation(x)\n",
    "        x = self.layers[-1](x)  # Apply the last linear layer (without ReLU if it's the output layer)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b037f440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: tensor([[0., 1., 0., 0.]], grad_fn=<MmBackward0>) mask used: Parameter containing:\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "output: tensor([[0., 1., 0., 0.]], grad_fn=<MmBackward0>) mask used: Parameter containing:\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [1., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]])\n",
      "output: tensor([[0., 1., 0., 0., 0., 0.]], grad_fn=<MmBackward0>) mask used: Parameter containing:\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [1., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "output: tensor([[0., 1., 0., 0.]], grad_fn=<MmBackward0>) mask used: Parameter containing:\n",
      "tensor([[1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "input_size = 4  # Adjust according to your model's expected input size\n",
    "neurons_per_layer = [input_size,  4, 4, 6, input_size]  # Symmetric for autoencoding\n",
    "num_samples = 100  # Number of synthetic data samples\n",
    "batch_size = 10  # Batch size for training\n",
    "epochs = 500  # Number of epochs for training\n",
    "\n",
    "# Generate synthetic data\n",
    "data = torch.randn(num_samples, input_size)\n",
    "dataset = TensorDataset(data, data)  # Using the same data as both input and target\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "model = DAGAutoencoder(neurons_per_layer)\n",
    "initial_adj_matrix = np.array([\n",
    "    [0, 1, 0, 0],\n",
    "    [0, 0, 0, 1],\n",
    "    [1, 0, 0, 1],\n",
    "    [0, 0, 0, 0]\n",
    "])\n",
    "initial_adj_matrix = np.array([\n",
    "    [0, 1, 0, 0],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 0]\n",
    "])\n",
    "initial_masks = [torch.from_numpy(mask).float() for mask in create_masks(initial_adj_matrix, neurons_per_layer)]\n",
    "model.set_masks(initial_masks)\n",
    "\n",
    "input_tensor = torch.ones((1, 4))\n",
    "o = torch.mm(input_tensor, (model.layers[0].weight * model.layers[0].mask).T)  \n",
    "print('output:', o, 'mask used:', model.layers[0].mask)\n",
    "o = torch.mm(o, (model.layers[1].weight * model.layers[1].mask).T)  \n",
    "print('output:',o,'mask used:',  model.layers[1].mask)\n",
    "o = torch.mm(o, (model.layers[2].weight * model.layers[2].mask).T) \n",
    "print('output:', o, 'mask used:', model.layers[2].mask)\n",
    "o = torch.mm(o, (model.layers[3].weight * model.layers[3].mask).T) \n",
    "print('output:',o, 'mask used:', model.layers[3].mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd230d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3ebb84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced67fc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99f7db2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c4679d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a23b3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ed03f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd641710",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fa216f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for inputs, targets in dataloader:\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)  # Multiply by batch size\n",
    "\n",
    "    # Print statistics\n",
    "    epoch_loss = running_loss / num_samples\n",
    "    if epoch % 10 == 9:  # Print every 10 epochs\n",
    "        print(f'Epoch {epoch + 1}, Loss: {epoch_loss}')\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "# Test the model with one example\n",
    "test_input = torch.randn(1, input_size)\n",
    "model.eval()  # Set model to evaluation mode\n",
    "test_output = model(test_input)\n",
    "print(\"Test input:\", test_input)\n",
    "print(\"Reconstructed output:\", test_output)\n",
    "\n",
    "intervention_adj_matrix = np.zeros_like(initial_adj_matrix) \n",
    "intervention_masks = [torch.from_numpy(mask).float() for mask in create_masks(intervention_adj_matrix, neurons_per_layer)]\n",
    "model.set_masks(intervention_masks)\n",
    "\n",
    "# Example usage after intervention\n",
    "output_after_intervention = model(test_input)\n",
    "print(\"Output of the network after intervention:\", output_after_intervention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb2373f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5454c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ca30d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c154eb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2d16ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "o\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570a985d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0729ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2389bb76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680745de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33124d12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7116f644",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171ab8ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866817b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b784a57e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba70ae08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e19edc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92774604",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63607829",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cc3fd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dad0951",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf73a75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3453bb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc89a84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp_gpt_env]",
   "language": "python",
   "name": "conda-env-nlp_gpt_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
